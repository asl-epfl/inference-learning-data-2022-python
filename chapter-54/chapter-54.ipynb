{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e58611b",
   "metadata": {},
   "source": [
    "# Chapter 54: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c64bfe5",
   "metadata": {},
   "source": [
    "### This code generates figures 3, 4, and 7 in Chapter 54: Decision Trees (vol. III)\n",
    "\n",
    "#### Runs simulations for Example 3 in the chapter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50b1a7",
   "metadata": {},
   "source": [
    "TEXT: A. H. Sayed, INFERENCE AND LEARNING FROM DATA, Cambridge University Press, 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7aced",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "DISCLAIMER:  This computer code is  provided  \"as is\"   without  any  guarantees. Practitioners  should  use it  at their own risk.  While  the  codes in  the text are useful for instructional purposes, they are not intended to serve as examples of full-blown or optimized designs.  The author has made no attempt at optimizing the codes, perfecting them, or even checking them for absolute accuracy. In order to keep the codes at a level  that is  easy to follow by students, the author has often chosen to  sacrifice  performance or even programming elegance in  lieu  of simplicity. Students can use the computer codes to run variations of the examples shown in the text. \n",
    "</div>\n",
    "\n",
    "The Jupyter notebook and python codes are developed by Saba Nasiri. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327853b7",
   "metadata": {},
   "source": [
    "required libraries:\n",
    "\n",
    "1. numpy\n",
    "2. matplotlib.pyplot\n",
    "3. scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee2864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5695ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function selects the most informative attribute to serve as node features: NxM, with each feature vector being a row of size 1xM and has binary values 0 and 1\n",
    "# \n",
    "# labels: +1 or -1 \n",
    "# \n",
    "# returns entropy (H), conditional entropy (cond_H), mutual information (mI) and normalized mutual information (mI_norm) for all attributes, as well Gini gain ratio (DG) and normalized Gini gain ratio (DG_norm),\n",
    "# and gamma_vec (what labels should be), number of errors (ne)\n",
    "\n",
    "def node_tree(features, labels):\n",
    "    \n",
    "    N = features.shape[0] # number of rows\n",
    "    M = features.shape[1] # number of columns\n",
    "    \n",
    "    probs = np.zeros((2, M)) #  each column has two probabilities: prob(x_m=0) and prob(x_m=1)\n",
    "    cond_probs = np.zeros((2, M)) # each column has two conditional probabilities: prob(x_m=0|gamma=1) and prob(x_m=0|gamma=-1)\n",
    "    \n",
    "    H = np.zeros((M,)) # entropy for each attribute\n",
    "    cond_H = np.zeros((M,)) # conditional entropy H(x|gamma) for each attribute\n",
    "    \n",
    "    mI = np.zeros((M,)) # mutual information for each attribute\n",
    "    mI_norm = np.zeros((M,)) # normalized mutual information each attribute\n",
    "    \n",
    "    G = np.zeros((M,)) # Gini impurity for each attribute\n",
    "    cond_G = np.zeros((M,)) # conditional Gini impurity\n",
    "    \n",
    "    DG = np.zeros((M,)) # Gini gain ratio\n",
    "    DG_norm = np.zeros((M,)) # normalized Gini gain ratio\n",
    "    \n",
    "    ne = np.zeros((M,)) # number of errors for each attribute\n",
    "    \n",
    "    gamma_vec = np.zeros((2, M)) # first row is gamma_1 and second row is gamma_0\n",
    "    gamma_1 = np.zeros((M,)) # if we end at attribute m, the entry gamma_1(m) tells us what the label (+-1) should be when x(m)=1\n",
    "    gamma_0 = np.zeros((M,)) # if we end at attribute m, the entry gamma_0(m) tells us what the label (+-1) should be when x(m)=0\n",
    "    \n",
    "    error_vec = np.zeros((2, M)) # first row is error_1 and second row is error_0\n",
    "    \n",
    "    N_p1 = 0 # how many features exist at class +1\n",
    "    N_m1 = 0 # how many features exist at class -1\n",
    "    a = 0\n",
    "    b = 0\n",
    "    \n",
    "    for n in range(N):\n",
    "        if labels[n] == 1 :\n",
    "            N_p1 = N_p1 + 1\n",
    "        else:\n",
    "            N_m1 = N_m1 + 1\n",
    "            \n",
    "            \n",
    "    prob_gamma_p1 = N_p1/N # probability of label gamma = +1\n",
    "    prob_gamma_m1 = N_m1/N # probability of label gamma = -1\n",
    "    H = np.zeros((M,))\n",
    "    G = np.zeros((M,))\n",
    "    \n",
    "    for m in range(M): # iterate over attributes\n",
    "        counter_0 = 0 # counts how many times x_m is at zero\n",
    "        counter_1 = 0\n",
    "        \n",
    "        counter_0_p1 = 0 # counts how many times x_m = 0 under class +1\n",
    "        counter_0_m1 = 0 # counts how many times x_m = 0 under class -1\n",
    "        \n",
    "        for n in range(N): # iterating over all data for each attribute m\n",
    "            x = features[n, m]\n",
    "            if x == 0:\n",
    "                counter_0 = counter_0 + 1\n",
    "            else:\n",
    "                counter_1 = counter_1 + 1\n",
    "                \n",
    "            if labels[n] == 1:\n",
    "                if x == 0:\n",
    "                    counter_0_p1 = counter_0_p1 + 1\n",
    "                    \n",
    "            else:\n",
    "                if x == 0:\n",
    "                    counter_0_m1 = counter_0_m1 + 1\n",
    "                    \n",
    "                    \n",
    "        p0 = counter_0/N\n",
    "        p1 = counter_1/N\n",
    "        probs[0, m] = p0\n",
    "        probs[1, m] = p1\n",
    "            \n",
    "        if p0 == 0:\n",
    "            a = 0\n",
    "        else:\n",
    "            a = -p0*np.log2(p0)\n",
    "            \n",
    "        if p1 == 0:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = -p1*np.log2(p1)\n",
    "            \n",
    "        H[m] = a + b # estimated entropy for m-th attribute\n",
    "        G[m] = 1-p0**2-p1**2 # estimated Gini impurity\n",
    "        \n",
    "        # we now estimate the conditional entropies\n",
    "        p0_m1 = 0\n",
    "        p0_p1 = 0\n",
    "        p1_p1 = 0\n",
    "        p1_m1 = 0\n",
    "        \n",
    "        if N_p1 != 0:\n",
    "            p0_p1 = counter_0_p1/N_p1\n",
    "            p1_p1 = 1- p0_p1\n",
    "        \n",
    "        if N_m1 != 0:\n",
    "            p0_m1 = counter_0_m1/N_m1\n",
    "            p1_m1 = 1-p0_m1\n",
    "        \n",
    "        cond_probs[0, m] = p0_p1\n",
    "        cond_probs[1, m] = p0_m1\n",
    "        \n",
    "        if p0_p1 == 0:\n",
    "            a = 0\n",
    "        else:\n",
    "            a = -p0_p1*np.log2(p0_p1)\n",
    "            \n",
    "        if p1_p1 == 0:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = -p1_p1 * np.log2(p1_p1)\n",
    "        \n",
    "        \n",
    "        cond_1 = a + b # estimated conditional entropy for m-th attribute under gamma=1: H(x_m|gamma=+1)\n",
    "        cond_1_Gini = 1- (p0_p1)**2 - (p1_p1)**2 # conditional Gini impurity\n",
    "        \n",
    "        if p0_m1 == 0:\n",
    "            a = 0\n",
    "        else:\n",
    "            a = -p0_m1*np.log2(p0_m1)\n",
    "            \n",
    "        if p1_m1 == 0:\n",
    "            b = 0\n",
    "        else:\n",
    "            b = -p1_m1*np.log2(p1_m1)\n",
    "            \n",
    "        cond_2 = a + b # estimated conditional entropy for m-th attribute under gamma=-1:  H(x_m|gamma=-1)\n",
    "        cond_2_Gini = 1 - (p0_m1)**2 - (p1_m1)**2 # conditional Gini impurity\n",
    "        \n",
    "        cond_H[m] = prob_gamma_p1*cond_1 + prob_gamma_m1*cond_2\n",
    "        cond_G[m] = prob_gamma_p1*cond_1_Gini + prob_gamma_m1*cond_2_Gini\n",
    "        \n",
    "        mI[m] = H[m] - cond_H[m] # mutual information\n",
    "        mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
    "        \n",
    "        DG[m] = G[m] - cond_G[m] # Gini gain ratio\n",
    "        DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n",
    "        error_1 = np.zeros((M,))\n",
    "        error_2 = np.zeros((M,))\n",
    "        \n",
    "    # estimating number of errors    \n",
    "    for m in range(M):\n",
    "        counter_p1_1 = 0 # how many labels +1 when x(m) = +1\n",
    "        counter_m1_1 = 0 # how many labels -1 when x(m) = +1\n",
    "        counter_p1_0 = 0 # how many labels +1 when x(m) = 0\n",
    "        counter_m1_0 = 0 # how many labels -1 when x(m) = 0\n",
    "        for n in range(N):\n",
    "            x = features[n, m]\n",
    "            if x == 1:\n",
    "                if labels[n] == 1:\n",
    "                    counter_p1_1 = counter_p1_1 + 1\n",
    "                else:\n",
    "                    counter_m1_1 = counter_m1_1 + 1\n",
    "            if x == 0:\n",
    "                if labels[n] == 1:\n",
    "                    counter_p1_0 = counter_p1_0 + 1\n",
    "                else:\n",
    "                    counter_m1_0 = counter_m1_0 + 1\n",
    "                    \n",
    "        if counter_p1_1 >= counter_m1_1: # will decide in favor of class +1 along this branch\n",
    "            ne[m] = ne[m] + counter_m1_1\n",
    "            gamma_1[m] = 1 # decide that class is +1 if we stop here when x(m)=1\n",
    "        else:\n",
    "            ne[m] = ne[m] + counter_p1_1\n",
    "            gamma_1[m] = -1 # decide that class is -1 if we stop here when x(m)=1 \n",
    "            \n",
    "        error_1[m] = ne[m] # how many classification errors will occur when x(m)=1\n",
    "        if counter_p1_0 >= counter_m1_0: # will decide in favor of class +1 along this branch\n",
    "            ne[m] = ne[m] + counter_m1_0\n",
    "            gamma_0[m] = 1 # decide that class is +1 if we stop here when x(m)=0;\n",
    "        else:\n",
    "            ne[m] = ne[m] + counter_p1_0\n",
    "            gamma_0[m] = -1 # decide that class is -1 if we stop here when x(m)=0;\n",
    "            \n",
    "        error_2[m] = ne[m] - error_1[m] # how many classification errors will occur when x(m)=1\n",
    "\n",
    "        \n",
    "    gamma_vec[0, :] = gamma_1\n",
    "    gamma_vec[1, :] = gamma_0\n",
    "    error_vec[0, :] = error_1\n",
    "    error_vec[1, :] = error_2\n",
    "        \n",
    "    return H, cond_H, mI, mI_norm, DG, DG_norm, ne, gamma_vec, error_vec\n",
    "                    \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bff8ca",
   "metadata": {},
   "source": [
    "## Figure 54.3 (Entropy and Gini impurity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802836cc",
   "metadata": {},
   "source": [
    "We explained in Example 6.1 that the entropy of a random variable reveals the amount of uncertainty we have about it.  For example, for a Boolean variable $x$, if it happens that $p=1$, then  we would expect to observe\n",
    "the event $x=1$ each time an experiment is performed on $x$. The entropy in this case is $H(x)=0$. A similar situation occurs when $p=0$, for which we would expect to observe the event $x=0$ each time an experiment is performed on $x$. The entropy again evaluates to $H(x)=0$. The case of most uncertainty about $x$ arises when $p=1/2$. In this situation, the events $x=1$ and $x=0$ are equally likely and the entropy evaluates to $H(x)=1$.  Figure 54.3 plots $H(p)$ versus $p$; it is seen that the function is concave, attains the value zero at locations $p=0,1$, and attains the maximum value of 1 at $p=1/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d2f28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 0\n",
    "H = np.zeros((np.arange(0, 1.01, 0.01).shape[0],))\n",
    "G = np.zeros((np.arange(0, 1.01, 0.01).shape[0],))\n",
    "for p in np.arange(0, 1.01, 0.01):\n",
    "    if p == 0:\n",
    "        H[nx] = -(1-p)*np.log2(1-p)\n",
    "    elif p ==1:\n",
    "        H[nx]= -p*np.log2(p)\n",
    "    else:\n",
    "        H[nx] = -p*np.log2(p) -(1-p)*np.log2(1-p)\n",
    "        \n",
    "    G[nx] = 2*p*(1-p)\n",
    "    nx = nx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "239cfc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAEnCAYAAACgxCtdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4SUlEQVR4nO3dd1hT5xcH8G/CVgEHCggoIgqIAioVcVtx74mzStW2Vq2Ku+5tXdWq1WqddeD41VFFHChOVKqCg+ECcYGKAwWFQO7vj9MEI6iACTeQ83me+xBubpI3vCQ5ee95zysRBEEAY4wxxhhjOkAqdgMYY4wxxhgrKBz8MsYYY4wxncHBL2OMMcYY0xkc/DLGGGOMMZ3BwS9jjDHGGNMZHPwyxhhjjDGdwcEvY4wxxhjTGRz8MsYYY4wxnaEvdgPEIJfL8ejRI5iamkIikYjdHMYYY4wx9gFBEPD69WuUL18eUqn6xmt1Mvh99OgR7OzsxG4GY4wxxhj7jPv378PW1lZt96eTwa+pqSkAIDY2FqVLlxa5NUzTZDIZjhw5ghYtWsDAwEDs5jAN4/7WLdzfuoX7W7c8f/4clSpVUsZt6qKTwa8i1cHU1BRmZmYit4ZpmkwmQ7FixWBmZsZvljqA+1u3cH/rFu5v3SKTyQBA7SmqPOGNMcYYY4zpDA5+GWOMMcaYzuDglzHGGGOM6QzRg99Tp06hffv2KF++PCQSCfbu3fvZ24SEhKBWrVowMjKCo6MjNm7cqPF2MsYYY4yxwk/04DclJQXu7u5YuXJlro6PjY1F27Zt0bRpU4SHh2PkyJEYNGgQDh8+rOGWMsYYY4yxwk70ag+tW7dG69atc3386tWrUalSJSxevBgA4OLigjNnzuDXX39Fy5YtNdVMxhhjjDFWBIge/OZVaGgofHx8VPa1bNkSI0eO/Oht0tLSkJaWpvw9OTkZAJXQUJTRYEWXoo+5r3WD1ve3XA4kJwPPnwMvX0Ly4gX9/uYNJG/eAG/eAK9fAykpkKSmAmlptL17B6Sn00+ZjO4nMxPIzIREcVkQAKkU0NODoKenvAw9PcDIiDZDQ8DYGDAygmBsDBQvDpQoAZQoAcHUlH43NQXMzSGUKgWUKgWULk230UJa399Mrbi/dYum+rnQBb8JCQmwtLRU2WdpaYnk5GS8ffsWJiYm2W4zb948zJgxI9v+EydOoFixYhprK9MuR48eFbsJrAAVZH9LMjJg/OIFjJOSYPz8OYxfvoTRy5cwfPUq63JyMgzfvIFBSgoFq5puk5rvL9PQEOklSiDd1BRpJUsizdycfpYsiXRzc7wrWRLvypTB2zJlICtRAijgpeP59a1buL91Q2pqqkbut9AFv/kxceJE+Pv7K39PTk6GnZ0dmjZtijJlyojYMlYQZDIZjh49iubNm3NRdB2gkf5+9QqIjYUkLg6Se/eAuDhI4uOBR48gefgQSEyERBDydJeCiQmNqJYsCcHMTDn6ClNTCCVK0Ahs8eLKEVvB2Dhr1NbAgEZzFSO7UiltEgmNCCtGghWXMzJo9Dg9HRLFKHJaGvD2LZCaSqPOr18rR5zx+jUkr14BL14AL15AIpdDLz0dJs+fw+T5c+Devc8/NxsbCDY29LNiRQj29oC9Pf20taXnoAb8+tYt3N+6JSkpSSP3W+iCXysrKyQmJqrsS0xMhJmZWY6jvgBgZGQEIyOjbPsNDAz4xaNDuL91S577+9Ur4ObN7Nvdu8DLl7l5QMDGBihfHrCyAsqVAywtaStXjrYyZSiNoFQpSN5LIyjYMdI8ksspKH7+nLakJCAxkbYnT7IuJyQADx8Cz55B8vYtcPs2JLdv53yfenoUADs6AlWrqm729oB+3j+a+PWtW7i/dYOm+rjQBb/e3t4IDAxU2Xf06FF4e3uL1CLGWKGSlATcuEFbZGTWzw++VGdjYQFUqkSbvT1QsSIFcIrNwoJGX4saqRQwN6etUqXPH//2LfDoEQXCDx4A9+8DcXFAbCxt9+7RqPO9e7QFB6veXl8fqFIFcHXN2qpVo8CYgx3GmBqIHvy+efMGt98bHYiNjUV4eDhKly6NChUqYOLEiXj48CE2b94MAPjhhx+wYsUKjBs3Dt9++y2OHz+OnTt34uDBg2I9BcaYNsrMBO7cAcLDs7aICBqh/BhrawqyqlTJGomsXJmC3RIlCqbdhZ2JCf3NKlfO+Xq5nPrg7l3g9m0aXb91K+vn27dAVBRtu3dn3U5fH3B2Bjw8VDczM80/J8ZYkSJ68Pvvv/+iadOmyt8Vubn9+/fHxo0b8fjxY8THxyuvr1SpEg4ePIhRo0Zh2bJlsLW1xZ9//sllzhjTZZmZQHQ0EBYG6YULaHj8OPR79aJAKicVK6qOLLq6Ak5OVOWAaZZUSqkh5csDDRqoXieX02hxVFTW6LxiZP71a+D6ddq2bFHeRN/WFnWsrSG9cgWoWxf46itKL2GMsY8QPfht0qQJhE9MFMlp9bYmTZrgypUrGmwVY0yrPX4MnDsHXLgAXLwIXLpEJcIA6AEorTiuWDHA3T1rlNDdnQJdHsXVTlIpUKECbe8PaAgCpU9cvao6kn/nDiQPHsD6wQMgLCzreAcHCoLr1AG8vYFatWjiIGOMQQuCX8YY+6TMTBr9O3uWAt6zZyl39EPFiwO1ayOzdm1ckUrh7ucHA2dnmlzFCjeJJCsobtcua39yMjIuX0bUli1wTU2F9NKlrEmKd+8CO3bQcUZGgKcnUL8+UK8ebWXLivNcGGOi4+CXMaZdMjNpVC8khLbTp6kSw/skEqBGDRrVq1OHNhcXQE8PcpkMDwMD4V61Kge+RZ2ZGYT69XH31Ss4t2kDqYEBlWe7dInOCFy4QF+Ynj2jL01nz2bd1sUFaNKEtsaNqSoHY0wncPDLGBOXINDp7GPHKNg9dYpWPHtfiRKUz6kYuatblyc6sZyVKgX4+NAG0P/XrVtZZw3OnaMcYsWkulWr6DhFMNy0KdCsGdVgZowVSRz8MsYK3qNHwNGjtB07lr3MmJkZ0KhR1sicu3u+ar8yBokkq3LHgAG0LymJzigozi5cvaoaDEsklCbRvDlt9erRAiOMsSKBP00YY5onk9Go28GDwKFDlMP7vmLF6NRzs2YU7Hp4cMoC05wyZYBOnWgDaPGO06eBEyfoy9iNGzSBLiwMmDuX8smbNAHatAHatqVqIYyxQouDX8aYZiQkUKAbGAgcOaKayvDhyJq3N8/GZ+IpXRro2JE2gBboOHZM9czEwYO0DR1KFUMUgXC9erz4BmOFDAe/jDH1iY4G9u6l7cIF1evKlgVat6agwceHa7Ey7WVjA/TvT5siJz0oiILfc+ey6g8vXEgr37VtC3TuDLRqxWX0GCsEOPhljOWfXE6nhvfsoYA3Jkb1+tq1KTBo25ZGeovi8r+saJNIKOfc3R0YP56qSRw+nJXCk5QEbNtGm5ERfbHr1Alo354rSDCmpTj4ZYzljVwOhIYCu3bR8rMPH2ZdZ2BAebuKD//y5UVrJmMaUaoU0LMnbZmZwPnz9MVvzx5aTluRHiGR0KTNHj2Arl05EGZMi3Dwyxj7PLmcPuR37aLt/YDX1JRGdjt1orQGLkHGdIWeHpXfq18fWLCASqgp0n7+/Rc4eZK24cNpQmf37kCXLhwIMyYyDn4ZYx937RqwdSud0r1/P2u/mRlNDureHWjRgierMSaR0EQ4V1dg0iTg3j06M7JzJy24ceIEbcOGAV9/DfTtS3nC/GWRsQLHwS9jTNWDBxTsbt1KE30UTE1VA15jY/HayJi2q1gRGD2atri4rEA4LIwqSBw7BvzwA72m+vQBWrbkWsKMFRAOfhljQEoKfThv2kRF/wWB9hsYUEpDnz5Au3Yc8DKWH/b2wJgxtN29S18ut2yhCaI7dtBWpgzlEfv5AbVq0UgyY0wjeOo1Y7pKEGjhiUGDACsrWv3qxAna37Ah8McfVKt3zx6gWzcOfBlTBwcHYPJkWk0uLAwYOZJygJOSgJUrqSqKuzuwdCnw9KnYrWWsSOLglzFdk5AAzJ8PODsDDRoA69YBb94AlSsDs2YBsbHAqVPAd99R8X/GmPopFnr59VdKNQoKopFfIyPKtR81iuoNd+kCHDhAlSUYY2rBaQ+M6QK5nHIM//gD2L8fyMig/cWLUw6vnx+N9vKpVsYKnr4+5fy2bEl1hAMCgA0bsmpo79kD2NrSWZpBgygoZozlG4/8MlaUJSbSKG+VKvTB+vffFPjWqwesXw88fkwfso0aceDLmDYoVQoYMoQqRFy7Bvj7Uz7wgwfA9OlAhQo0SS4wkEeDGcsnDn4ZK2oUubw9ewJ2dsDEiTTJxtyc6o1eu0bX+/lRBQfGmHaqXh1YvJgC361b6UuqXE5nb9q2pVSlX36hfGHGWK5x8MtYUfHuHY3i1q5Nubw7dgAyGeDlRaO8jx4Bv/1GH6iMscLD2Bjo3ZsWzIiMpElypUpRLeEJEyglYuBAIDxc7JYyVihw8MtYYXf/Po3u2toC334LXLlCH5bffgtcvkwrs/n5AcWKid1SxtiXcnGhSXIPH9KX2po16Yuv4nLDhlRPWJHXzxjLhoNfxgqrS5doNKhSJcrrTUqifMD58+k06bp19GHIGCt6TEzoS+2lS8CZM4CvL02cU1yuXBlYsgRITha7pYxpHQ5+GStM5HIqe9S0KZVJ2r6dJr00bkyT2e7cAcaPpwkyjLGiTyIB6tenChFxccCUKUDZskB8PK0uZ2cHjB2rujw5YzqOg1/GCoO0NGDtWsDVFWjfnlZh09enldcuXaLfO3emfYwx3WRjA8ycSbnAa9ZQLe/kZGDRIlpco08fzgtmDFznlzHt9vo11eZdsoTKkgGAmRnw/fdUucHOTtz2McbU6uXLl1izZg0MDAxgamoKMzMzmJmZKS+//9PAwCDnOzExAQYPpklwhw5RxYgTJ2hZ5W3bgNataZ5Aw4YF++QY0xIc/DKmjZKSqDLD8uVU9B6gCW3+/lTknkuUMVYknT9/HuPHj4eegSEyZemfPParr+rg4sULHz9AKqWSaG3b0uTXRYuoCsyhQ7TVr09BcJs2XOeb6RQOfhnTJo8fAwsX0mhvairtq1qVyhn16QMYGorbPsaYWqSlpeHmzZuIjo5GVFQUoqKicO16JG7dugkAKNtrPgwtK0OQpUGeloq0h5FIDtuH9McxAIC63vUwbuyY3D9grVo06jtrFr3HbNhA9b7btQPc3ICffwa6dQP09DTxdBnTKhz8MqYNHj2iYvV//EH5vQBVavj5Z8rl5Q8kxgqlV69eKYPb6OhoREZG4tqNKNy/Fwu5XJ7jbSQGRhBkaRBk75ASeRJvrx/D20c3UcaiLPzGjMHAgQPh7OycvwZVrgysXg1MnUol01avBq5epUVxqlWj/RwEsyKOg1/GxPTwIQW9a9ZkBb316wOTJ9NyxHwqkjGtJwgCHj9+rAxyo6KicCMyCpFRUXiamJDr+5Hq6aGivQOeJibg2cFfgXevIGTI0LJVKwxeMR/t2rX7eJ5vXpUvTyPAEydSetXSpbSARs+eVEt46lSge3cOglmRxMEvY2J4/BiYN0816G3QAJg+Hfj6aw56GdNCGRkZiI2NVQlyr0dGIToqCilvXuf6foxNiqFKlaqoUb0aXFxclJujoyMMDQ0xatQo7P/nIAZ+OwL9+/eHjY2N5p5U6dLAtGm0atxvv9Hk2qgooFcvYMYMCoJ9fSl/mLEigoNfxgpSUhKwYAGNtLx9S/saNKAPmaZNOehlTAukpqbi5s2bygA3MjIK127cQOydO5B9ZhLa+0qWLoNqLi5wreaiEuTa2dlB+olg8tdff8Wvv/6qjqeSe+bmVCP4p5/o/WnJEiA6mhbSmT8fmD2b8oP5PYoVARz8MlYQXr+m04qLFmWtuFSvHk0+4aCXMVEkJSUpc3EpVSES129E4dGDeAiCkOv7KW9bAdVdXeBarRqcnZ2VQa6FhYUGW68h5uaUdvXTTzQSvGgR5QR36ADUrQvMnUvvWYwVYloR/K5cuRILFy5EQkIC3N3dsXz5ctSpU+ejxy9duhSrVq1CfHw8LCws0K1bN8ybNw/GxsYF2GrGcuHdO5pQMncu8PQp7XN3p99bt+aglzENEwQB9+/fV5l0dv1GJCKjovAi6Vmu70ffwACVHBxRw7Uaqr03klu1alUUL15cg89AJGZmFAQPHUq5wcuWAefPU1qWjw8wZw7wic9pxrSZ6MHvjh074O/vj9WrV8PLywtLly5Fy5YtERMTg3LlymU7ftu2bZgwYQLWr1+PevXq4ebNmxgwYAAkEgmWLFkiwjNgLAdyOZUVmjSJlhkFgCpVaKS3e3fOn2NMzWQyGW7fvq0S5F67EYmbMdF4qygbmAvFSpSAs7MLqn+QquDg4AB9XVxBsVQp+rL+008U8P7xB3DsGG3du9PchcqVxW4lY3ki+it5yZIlGDx4MPz8/AAAq1evxsGDB7F+/XpMmDAh2/Hnzp1D/fr10bt3bwCAvb09evXqhQsXPlHom7GCFBwMjB0LXLlCv9vY0ES2AQN4+WHGvtCbN29UauNev3EDYf9extMnCcjMyMj1/ViUs0Q1FxdUd1VNVShfvjwkfEYmOysrygUePZrezzZvBnbtAvbuBX78kUaJC2OaB9NJon4Sp6en49KlS5g4caJyn1QqhY+PD0JDQ3O8Tb169bBlyxZcvHgRderUwd27dxEYGIh+/fp99HHS0tKQpphRDyD5v5xLmUwGmUympmfDtJWijzXe19evQ+/nnyENCgIACKamkI8bB/lPP9Fyo4IA8P+bxhVYfzONEQQBT548QUxMDKKjo/+rjxuFG1FRSHz8KNf3I5VKYVuhIk04+y/AdXZ2hpOTE0qWLJnjbTLyEEDrJBsbYO1aYPhwer87cgRYtgzCxo30fjdsGL3faQi/vnWLpvpZIuQlq1/NHj16BBsbG5w7dw7e3t7K/ePGjcPJkyc/Opr722+/YcyYMRAEARkZGfjhhx+watWqjz7O9OnTMWPGjGz7t23bhmLFin35E2E6zejlSzhv3YqKwcGQyOWQ6+khrlUrxPTogXRzc7Gbx5jWksvlePLkCR48eKDc4u/Tz9SUN7m+H30DQ1iXL4+Kdrawtc3aypcvD0NeFVGjyoaHo9qmTSgZGwsASLWwQGS/fnjYqBHPaWBfLDU1Fb1798arV69gZmamtvstdMFvSEgIevbsidmzZ8PLywu3b9/GiBEjMHjwYEyZMiXHx8lp5NfOzg6PHz9GmTJl1P/EmFaRyWQ4evQomjdvrr4C8QCQlgbpihWQzp0LyWuq8Snv3BmZs2dTfi8Thcb6m+Xb+0v5RkdHIyYmBtdvROH27VtIT3uX6/sxNS8JZ2dnVK/mAicnJzg7O8PR0RExMTFo1aoV97dY5HJItm6F3rRpkDx4QLu8vSFfvBiCp6daH4pf37olKSkJ1tbWag9+RU17sLCwgJ6eHhITE1X2JyYmwsrKKsfbTJkyBf369cOgQYMAADVq1EBKSgq+++47TJo0KcfaiUZGRjAyMsq238DAgF88OkRt/S0IwD//AP7+wJ07tM/TE1i6FNL69cFT2bQDv74L3vtL+Sq2zy3lmxMraxu4/lc6TJGq4OLignLlymXLx1VMdOP+Ftm339LCGEuWAHPnQhoaCmm9ejTXYe5cwNparQ/H/a0bNNXHoga/hoaGqF27NoKDg9GpUycAdBosODgYw4YNy/E2qamp2QJcvf+WXxRxEJvpihs3gFGjgKNH6XcrK5rt/M03XMGB6YSclvK9HhmJqKjoPC/la1/JATVcXZWlw5ydneHs7AxTU1MNPgOmMSYmVOFmwABaNvmvv4CNG4Hdu2n/yJEAlyRlWkD0qef+/v7o378/PD09UadOHSxduhQpKSnK6g/ffPMNbGxsMG/ePABA+/btsWTJEtSsWVOZ9jBlyhS0b99eGQQzpnavX9MM52XLgMxMwNCQRn5//hngD2pWBGVkZODu3bsqlRWu3YhETHR0npfyrVrVKdtSvpUrV+Z83KLKxoaqQfz4IzBiBHDxIgXD69YBK1YALVuK3UKm40QPfn19ffH06VNMnToVCQkJ8PDwQFBQECwtLQEA8fHxKiO9kydPhkQiweTJk/Hw4UOULVsW7du3x5w5c8R6CqwoEwRgxw4q7/Pov1nmHTsCixdzbUtWJKSmpiImJkZZGze/S/mWKmOR41K+tra2n1zKlxVhdesCoaHA1q3AuHHA7dtAq1ZAly7Ar78CFSqI3UKmo0QPfgFg2LBhH01zCAkJUfldX18f06ZNw7Rp0wqgZUynRUfT6kbHj9PvlStTncvWrcVtF2P5oFjKVxHk5ncpXxu7ijku5cuTh1mOpFKgXz8aNJg+nZZM/vtvICgImDKFzqDxGQBWwLQi+GVMq6Sm0kpsixdTXV5jYzplN24c56sxrfbhUr5RUVG4ERmVr6V8HSo7ZsvHdXJy4vKQLH/MzGgy3IABNKhw5gy9r27aBKxcScsmM1ZAOPhl7H1HjgA//AD8V7MSbdvSSIWDg7jtYuwjHjx4gEmTJiE84hpu3YrJ11K+NVyz8nGdnZ11dylfpnlubsCpUzQZbuxYOsPWrBkFxYsWAXwGgRUAfndjDACePKHTb1u30u92dpTi0KEDF2pnWi0sLAybN2/+5DFlLa3g4uKM6tVUJ51ZW1vzUr6s4EkkVCGnQweaNLx6NVWFOHAAWLoU6N2b33eZRnHwy3SbINBpt9GjgefP6Q33p58o7YGrODANWbduHXbs2IEjR47k+jY9e/bEV199hdGjR6vsd3d3h0QigUQigV3FSqju6oJq7wW4zs7OH13KlzFRlSwJ/P470Lcv8N13VEqyb1+qFLFqFZ9xYxrDU3CZ7rpzB/DxAfz8KPB1dwfOn6eRBw58tcb06dPh4eEhdjM+aePGjR8NMCUSCfbu3av8/d27d5gyZUqeJ+1OnjwZc+bMwatXr1T2Ozg44NGjR0hJSUHc3ds48M8/WLBgAfz8/FC3bl0OfJn2q1cPuHwZmD0bMDKi9LPq1YGFC4GMDLFbx4ogDn6Z7pHLqV5vjRpUycHYGPjlFyAsDKhTR+zWsXySyWRiNyFXdu/eDTMzM9SvXz9Pt6tevToqV66MLVu2ZLvOysoKxjwZkxVmhoa0EMbVq0CTJsDbtzTJuF49GhFmTI04+GW65dYtoHFjWmno7VugaVPg+nV6k+WlMtVOLpdj3rx5qFSpEkxMTODu7o7du3crrw8JCYFEIkFwcDA8PT1RrFgx1KtXDzExMQBoRHXGjBmIiIhQntrfuHEjABpRXbVqFTp06IDixYsra33/8ccf+P7771G8eHE4OTnhr7/+UmmT4natW7eGiYkJHBwcVNr09ddfZyu9+PTpUxgaGiI4OPiL/yYBAQFo3769yr4BAwagU6dOmDFjBsqWLQszMzP88MMPSE9XrbPbvn17BAQEfHEbGNNaVavSoMS6dYC5OQ1K1KpFK2nyKDBTEw5+mW7IzIR06VKaaXzmDFCiBOWUHTvGi1Vo0Lx587B582asXr0aN27cwKhRo9C3b1+cPHlS5bhJkyZh8eLF+Pfff6Gvr49vv/0WAC2CM3r0aLi6uuLx48d4/PgxfH19lbebPn06OnfujGvXruHbb7/Fnj174O/vj44dO+LKlSv4/vvv4efnhxMnTqg83pQpU9C1a1dERESgT58+6NmzJ6KiogAAgwYNwrZt25CWlqY8fsuWLbCxscHXaijHdObMGXh6embbHxwcjKioKISEhGD79u34+++/MWPGDJVj6tSpg4sXL6q0jbEiRyIBvv2WRnzbtgXS02liXN26wLVrYreOFQWCDnr16pUAQHj27JnYTWEFIP3aNSHJyUkQaHqbIPj4CEJcnNjNKvLevXsnFCtWTDh37pzK/oEDBwq9evUSBEEQTpw4IQAQjh07prz+4MGDAgDh7du3giAIwrRp0wR3d/ds9w9AGDlypMq+evXqCQMHDhT27t0rpKenC4IgCN27dxfatGmjcrsffvhB5XZeXl7CkCFDBEEQhLdv3wqlSpUSduzYobzezc1NmD59+kef64YNGwQAQvHixbNtAIQ9e/YIgiAIL168EAAIp06dUrl9//79hdKlSwspKSnKfatWrRJKlCghZGZmKvdFREQIAIQ4/v9VSk9PV+lvVsTI5YKwaZMglCwpCIAgNzAQInv1EtLfe62wouvZs2cCAOHVq1dqvV8e+WVFl1wOrFgB/Tp1UDomBoKpKbBmDU2mqFhR7NYVebdv30ZqaiqaN2+OEiVKKLfNmzfjzp07Kse6ubkpL1tbWwMAnjx58tnH+HAENSoqCt7e3ir76tevrxzVVfjwGG9vb+UxxsbG6NevH9avXw8AuHz5Mq5fv44BAwZ8si2mpqYIDw/Ptr3v7du3ysf4kLu7u8oCEt7e3njz5g3u37+v3GdiYgKAliRmTCcoyqJFRgIdOkAik8Fl+3boNW4M/JcexVhecakzVjQ9fEhVHI4ehQTAE3d3lPrf/2DAKQ4F5s2bNwCAgwcPwsbGRuU6IyMjld8N3su3VtSdlcvln32M4sWLf2kzczRo0CB4eHjgwYMH2LBhA77++mtU/MwXJqlUCkdHx08eU6ZMGUgkErx48SJf7Xr+/DkAoGzZsvm6PWOFlrU1sHcvMjZvhnzoUBj++y9QsyawYAGtGMd1gVke8MgvK3oCAqiSw9GjgLExMpcuRei0aUCFCmK3TKdUq1YNRkZGiI+Ph6Ojo8pmZ2eX6/sxNDREZmZmro51cXFBaGioyr6zZ8+iWrVqKvvOnz+f7XcXFxfl7zVq1ICnpyfWrl2Lbdu2KXOQv5ShoSGqVauGyMjIbNdFREQoR4YVbSpRooTK3+r69euwtbWFhYWFWtrDWKEikUDo3Rsnli2D3MeHJi0PHw60akUDHozlEo/8sqLjxQvgxx8p+AUAT0/gr78gr1wZCAwUt206yNTUFGPGjMGoUaMgl8vRoEEDvHr1CmfPnoWZmRn69++fq/uxt7dHbGwswsPDYWtrC1NT02wjxwpjx45Fjx49oK+vjypVqiAoKAh///03jh07pnLcrl274OnpiQYNGmDr1q24ePEi1q1bp3LMoEGDMGzYMBQvXhydO3fO3x8hBy1btsSZM2cwcuRIlf3p6ekYOHAgJk+ejLi4OEybNg3Dhg2DVJo1RnH69Gm0aNFCbW1hrDB6Z2GBzAMHIF2zhir1HDlCAx6rVgHvTYhl7GN45JcVDSdPUiWHgABATw+YNg04dw5wdha7ZTpt1qxZmDJlCubNmwcXFxe0atUKBw8eRKVKlXJ9H127dkWrVq3QtGlTlC1bFtu3b//osZ06dcKSJUuwd+9eeHh44I8//sCGDRvQpEkTleNmzJiBgIAAuLm5YfPmzdi+fXu20eFevXpBX18fvXr1UmsN3YEDByIwMDDbYhXNmjVDlSpV0KhRI/j6+qJDhw6YPn268vp3795h7969GDx4sNrawlihJZXSqO+VKzTQ8eIF0LMn0K8f8Pq12K1j2k6t0+cKCa72UITIZIIwZYogSCRUyaFKFUG4cEHlEJ4Nrls+1994r/rCp8TGxgpSqVS4dOmSmlsoCN26dRPmzp2r/L1///5Cx44dP3mb33//XWjevLna21LY8etbt+TY3+npgjB1qiBIpfQ5ULmyIFy8KF4jmdpwtQfGPhQXRwtWzJpFRcy+/ZaWyORV2tgXkMlkSEhIwOTJk1G3bl3UqlVL7Y+xcOFClChRIk+3MTAwwPLly9XeFsYKPQMDYMYM4NQpmttx5w6tDLdwIVX9YewDHPyywmnnTsDDg1IbzMwo3WHdOlq8grEvcPbsWVhbWyMsLAyrV6/WyGPY29tj+PDhebrNoEGD4OTkpJH2MFYk1K8PhIcD3bvTanDjxtFkuMePxW4Z0zI84Y0VLqmpwE8/UaALAN7ewNatQB5ySJluEwThk9c3adLks8eom2LJZsbYFypVCtixA2jRAhgxgqr+uLsDmzdTIMwYeOSXFSYxMYCXFwW+EgkweTKd5uLAlzHGmIJEAgwaBFy6RIHv06dA69bApEk0Isx0Hge/rHDYvp1m9F6/DlhaAsHBlOurzycvGGOM5cDZGTh/nhbBAIC5cwEfH06DYBz8Mi337h0wZAjQuzfw5g3QpAnldDVtKnbLGGOMaTtjY2DFCpoXUqIElcX08ACOHxe7ZUxEHPwy7XX3Lk1gWL06K83h2DHAykrsljHGGCtMfH0pDaJGDeDJExoBnjWLq0HoKA5+mXbavx+oVYtKl1lYAIcO0RuVnp7YLWOMMVYYVa0KXLgADBxI5TGnTgXatAGSksRuGStgHPwy7SKX0+psHTsCr15RrcYrV4CWLcVuGWOMscLOxAT4809g0ya6fPgwzScJDxe7ZawAcfDLtMfLl0D79sDMmfT7sGHAiROAra2ozWKMMVbEfPMNTYZzcKAFk+rVo7KZTCdw8Mu0w/Xr9O07MJAmKGzaBCxfDhgait0yxhhjRZGbGxAWRvV/374F+vYFRo4EZDKxW8Y0jINfJr4dO6h+7507QMWKwNmz9K2cMcYY06TSpYEDB6gGMAAsW0aT4RITxW0X0ygOfpl45HJg4kSgZ09auc3HB/j3X5roxhhjjBUEPT1g9mxgzx7A1JQWT6pdm6pDsCKJg18mjtevgU6dgPnz6fexY6mig4WFqM1ijDGmozp1Ai5epMUxHj4EGjYEdu4Uu1VMAzj4ZQUvNpYmF/zzD2BkRJMMFizg1doYY4yJS7EqXOvWlAfs60sViLgecJGSr+A3LCwMzZo1g5ubG7p06YKZM2di//79iI+PV3f7WFFz6hRQpw5NcLOyotV2evcWu1WMMcYYMTenwZnRo+n3mTMpCE5JEbddTG3yFfz269cPenp6+O6771CpUiWcPHkSfn5+sLe3R5kyZfJ8fytXroS9vT2MjY3h5eWFixcvfvL4ly9fYujQobC2toaRkRGqVq2KwMDA/DwVVpDWraO83mfPKK83LIwmujHGGGPaRE8PWLQIWL8eMDAAdu+mNIj798VuGVODfJ1nvn//Pg4ePIjKlSur7L937x7C81goeseOHfD398fq1avh5eWFpUuXomXLloiJiUG5cuWyHZ+eno7mzZujXLly2L17N2xsbHDv3j2ULFkyP0+FFYTMTGDcOGDJEvq9e3dg40agWDFRm8UYY4x9kp8fUKUK0KULLbj01Vc0KvzVV2K3jH2BfI38ent74+HDh9n2V6xYER07dszTfS1ZsgSDBw+Gn58fqlWrhtWrV6NYsWJYv359jsevX78ez58/x969e1G/fn3Y29ujcePGcHd3z89TYZqWmkrBriLwnT6dSptx4MsYY6wwaNCAzlS6uVEJtMaNgX37xG4V+wL5GvkdNWoUZs6ciZ07d6J06dL5fvD09HRcunQJEydOVO6TSqXw8fFBaGhojrfZv38/vL29MXToUOzbtw9ly5ZF7969MX78eOjp6eV4m7S0NKSlpSl/T05OBgDIZDLIuJi15jx5Ar3OnSENC4NgaIjMP/+E0LMnkJFRoM1Q9DH3tW7g/tYt3N+6RbT+Ll8eOHECer17Q3r4MITOnSFfvBjyYcMKth06RlP9nK/gt3379pBIJKhatSo6duwIb29v1KxZEzVq1IBhHlbkevbsGTIzM2Fpaamy39LSEtHR0Tne5u7duzh+/Dj69OmDwMBA3L59Gz/++CNkMhmmTZuW423mzZuHGTNmZNt/4sQJFOMRSI0o8eAB6s6aheKJiUg3NcWFCRPw3MyMVnATydGjR0V7bFbwuL91C/e3bhGrvyXffQc3QYD9kSPQ8/dH3PHjuO7nRznCTO1SU1M1cr8SQRCEvN7o7t27iIiIQHh4OK5evYqIiAjExcXBwMAATk5OuHr1aq7u59GjR7CxscG5c+fg7e2t3D9u3DicPHkSFy5cyHabqlWr4t27d4iNjVWO9C5ZsgQLFy7E48ePc3ycnEZ+7ezs8Pjx43xN0GOfJjl9GnrdukHy4gUEBwdk7NsHODmJ1h6ZTIajR4+iefPmMDAwEK0drGBwf+sW7m/dohX9LQiQLl4MvZ9/BgDIO3RA5ubNnM6nAUlJSbC2tsarV69gZmamtvvN18ivg4MDHBwc0LlzZ+W+5ORkRERE5DrwBQALCwvo6ekh8YNlBBMTE2FlZZXjbaytrWFgYKCS4uDi4oKEhASkp6fnOPJsZGQEIyOjbPsNDAz4zVLdtm2jCQLp6UDdupDs3w+DsmXFbhUA7m9dw/2tW7i/dYvo/T1xIuDgAPTvD+n+/ZA2b04T4T44k82+jKb6OF8T3jIyMjBnzhx4e3ujVq1a6N+/Py5cuICGDRti6NChub4fQ0ND1K5dG8HBwcp9crkcwcHBKiPB76tfvz5u374N+XsFp2/evAlra+s8pVwwDViyBOjThwLfrl2B48cBLQl8GWOMMbXy9QWOHQNKl6YJcfXrA3fvit0qlgv5Cn4nTJiA33//Hc2aNUOnTp2QlpaGdu3awc/PD3nNovD398fatWuxadMmREVFYciQIUhJSYGfnx8A4JtvvlGZEDdkyBA8f/4cI0aMwM2bN3Hw4EHMnTs3T0E3UzNBoFJmioLgI0fSkpAmJqI2izHGGNOoBg1oRbhKlYA7d2j10jyWfGUFL19pD9u2bUNAQAAaNWqk3BcbG4t27dph0aJFGDt2bK7vy9fXF0+fPsXUqVORkJAADw8PBAUFKSfBxcfHQyrNitHt7Oxw+PBhjBo1Cm5ubrCxscGIESMwfvz4/DwV9qVkMmDwYGDTJvr9l1+AsWMBiUTcdjHGGGMFoUoV4OxZWhI5IgJo1IhKoTVtKnbL2EfkK/hNSUmBra2tyr5KlSph+fLl+P777/MU/ALAsGHDMOwj5UJCQkKy7fP29sb58+fz9BhMA1JSgB49qIKDnh7w55/AgAFit4oxxhgrWNbWwMmTQMeO9LNVK2DrVqBbN7FbxnKQr7SHBg0aYJNipO89lSpVwqNHj764UawQSEqipYoDAym9Ye9eDnwZY4zpLnNzICiIVoNLT6fBodWrxW4Vy0G+gt9ffvkFS5cuxU8//YRbt24BoPIjy5cvR7Vq1dTaQKaFHj6kNc7PnwdKlaKE/3btxG4VY4wxJi5jY5rz8v33NB9myBBg5ky6zLRGvoLf6tWrIyQkBKGhoXBycoKxsTGKFSuGv/76C0uXLlVzE5lWiY2lwDcqCrC1Bc6coQR/xhhjjFEa4KpVgGLhrWnTaC4MB8BaI185vwBQs2ZNhIWFITo6GpGRkTA1NYWXl5daixAzLRMdTakODx8ClSsDwcFAxYpit4oxxhjTLhIJMH06lUEbMQJYvJjmyaxcCUjzNe7I1CjXPdCvXz+8ffsWAFVgUHB2dkaXLl3QvHlzDnyLsvBwmsH68CFQrRpw+jQHvowxxtin/PQTsG4dBcOrVwP9+wMZGWK3SufleuS3ePHiSEtLg4mJCezt7VGqVCm4ubnBw8MD7u7u8PDwgKurK6+wUxSdP08lXF6+BGrVAg4fBiwsxG4VY4wxpv2+/ZaWPu7XD9iyhUaAt28Hclh5lhWMXAe/q9+bsRgbG4uIiAiEh4cjIiIC+/fvR1xcHPT19eHs7IyIiAiNNJaJ4MQJoH17erHWq0fVHczNxW4VY4wxVnj07EkBcPfuwJ49VBLt779pHytw+cr57dWrF4KCgtChQwflvtevXyM8PBxXr15VW+OYyA4fBjp1At69A5o1o6LdxYuL3SrGGGOs8OnQATh4kALfw4eBNm2AAweAEiXEbpnOyVfW9fnz5/Hu3TuVfaampnB3d1fJB2aFWFAQvUDfvaMyZgcOcODLGGOMfQkfH+DIEcDMjBbDaNMGePNG7FbpnDwFv926dcP8+fMhkUjw5MmTbNenpKRg0aJFamscE0lQEI34pqVRAPy//1HtQsYYY4x9mfr1swLg06c5ABZBntIeKlSogAMHDkAQBLi7u6NMmTJwd3dXTniLiYmBtbW1ptrKCsL7gW+nTsCOHYChoditYowxxooOLy8KgFu0yAqAAwM5BaKA5Cn4XbJkCQDA0NAQZ8+exaNHj3DlyhWEh4djz549kMvlWLBggUYaygrAoUMU8KanA507AwEBHPgyxhhjmuDlBRw9mhUAt25NAbCpqdgtK/LyNeEtJSVFWdKsY8eOam0QE8mHge+OHQCXrWOMMcY0p06drBHgM2eyRoA5ANaofAW/YWFhMDMzQ/Xq1dXdHiYGRapDejrQpQuN+HLgy5havHsHvHpFZbLfvFHdXr+mn2/fZm3v3mVdTk8HZLKsn4otMxOQy7M2Qcj6KZVSPX2pVHXT16eXtaEh/VRsxsaAiUnWT8Xl4sXp87dEiazN1JS2kiUpXZEXqmJMDerUoRHg5s0pAG7dmj6XOQVCY/IV/A4dOhTDhg3LFvzeuXMH5cqVgyl/Yyk8QkJopJcDX8Y+KTMTePYMePIESEwEnj4FkpKyby9eUKCrCHjT0sRuueaYmVHZ75IlaStTJuetXDnA0pJ+lihBwTlj7D1ffZUVAJ89S5PNDx7kyeYakq/gNyYmBk2aNMm2/9ixY/jnn39w4MCBL20XKwjnz1MZs3fvaCELDnyZDpLJgEePPr4lJFCw++wZjazmh0RCgeL7I6mKy8WLU537nEZfjYyyRmjfH7HV06NNMcKr+AlQGxUjwYrR4MxMWlH1w1Hk9HQKznMadU5JyT5S/eYNBfWKSpfJybTdv5/7v4WJSVYwbG0NlC9Pm42N6uVSpThIZjrmq6+o/q+PD3D8ONCtGy2EwXNv1C5fwa+ZmRlevHiRbX/Dhg0xadKkL24UKwBXrgCtWtEnnI8PsHMnB76sSHrzBoiNpS0uDoiPp2BN8fPxYwoSc0MiyRrJLFuWVvn+cJSzdOmskdCSJWlk1NS0aKUIpKVREKwY3X75kka8cxoJf3+0XBFY37tH26cULw7Y2QEVKmT9rFABqFSJNhsb+gLAWJHi5UV19Vu1opHfvn2Bbdsob4mpTb7+mq1atcKiRYsQEBCgsl8qlSI9PV0tDWMaFBlJyfWvXgENGgB79/KpFVZoCQIFVrduAbdvA9HRUpw964nZs/UQF0fB1+cYGKiOPCo2a2vaFCOVFhb8GQTQiHS5crTlxZs3WYFwYiKNqj98qDrS/vAhBc0pKUB0NG05MTCgYNjeXg96eu6IipLCyQlwdAQqV+ZVY1kh1rgxLYHcoQOwaxf9M69fX7S+QYssX2/js2bNQp06ddC1a1dMnz4dNWrUwLt37/DLL7/Azc1N3W1k6nTnDo30PnsGeHryym2s0HjzBrh5Mysgio6m32/fpkApix4AG5XblipFo4X29kDFiqojiXZ2FMTx54rmKVI+HBw+fdzbt8CDB6qj9PHxNFocG0uXZTJ6O7tzRwrAHkeOqN6HjQ0Fws7OqluFCtzXrBBo1YqqLnXvDmzaRJ/TK1ZwLpCa5Cv4tbOzw/nz5zFkyBC4u7vDyMgIGRkZMDc3xz///KPuNjJ1iY8HmjWj87zVq9NsUnNzsVvFmIrkZDo5ceMGbdevU6D7qbxSqZSCWhr1y0RaWhTatHGGo6M+KlXif/PCxsQEqFKFtpxkZtIocWwscOtWBo4cuQOJpAru3pXi1i1Kw3j4kLaTJ1Vva2wMODkB1aoBrq5Zm4MDp1EwLdO5M7B5M6U+/P47BcC//MIBsBrk+wRexYoVERgYiHv37iEiIgIGBgbw8vJC6dKl1dk+pi7PnlGqw717QNWqwLFjlKDImEgyMmjk9upVICKCfl6/Tt/RPqZs2awRPCcn2qpUoRFdIyM6RiaTIzDwDtq0ceI09iJKT49G7O3sAG9vARYW0WjTxgEGBlIIAvD8OaXB3LoFxMRknSm4dYsm60VE0PY+Y2PAxQWoUQNwdwfc3Ohn2bLiPEfGAAC9ewOpqcDgwcDChXQaa+JEsVtV6H1x9lrFihVRsWJFdbSFacqbN0DbtvQpYGdHga+lpditYjokNZWCjcuXaYuIoFFdRdWAD1lb08kJxahctWoU6PL3NfY5ikmJZcoAdeuqXpeRQd//o6JUzyxERdH/4pUrtL3P2pqCYA8PoFYtoHZtSqHhwTdWYAYNos/xUaOAn3+mz+9vvxW7VYVavhe5mDBhAp4+fQpHR0d4eHgotwoVKqi7jexLyGRULuXiRZqGfuQIBcCMaUhqKgUQ//4LXLpEwW5UVM4VFYoXVx1pq1GDgl0+gcQ0QV+fJsNVrkxVHhUyM4G7dykQvnYta2T4zh3KEnv8mLLEFEqWBGrWpEC4Vi1ao8DBgQNipkEjR9Is0fnzaRTYwoImxLF8yVfw269fP1SoUAHfffcdYmNjcfLkSSxbtgwvXrxAqVKlkJSUpO52svyQy+nb4eHDNFs0MJDOFzOmJhkZlJ978WLWdv06BRMfsrKiYKFmTRpFc3engIEnHzGx6ell5Rh37py1//Vr+n+OiKAvdJcvU3rOy5fAiRO0KZQuTUHwV19l/eQTbEyt5s6lcinr1wO+vnQWt359sVtVKOUr+L1//z4OHjyIypUrq+y/d+8ewsPD1dEu9qUEARg7FtiyhYY7/vc/qh/I2Bd49ozWRgkNBc6dA8LCPqy0QKyt6cO/du2s0TFr64JvL2NfwtQU8PamTUEmoy98irMaYWFAeDjlGQcFqY4QV6qUdft69ejsBpfKY/kmkQB//EEB8IEDdPri9GnKEWN5kq+Xobe3Nx4+fJgt+OX8Xy2yaBGwZAldXr+eyqYwlgeCQBPSzpyh99dz52jC0IdMTbNGuxSbjU324xgrCgwM6KyFu3tW2mV6Oo0Ih4VlnQGJispaXGXbNjquWDF6rdSvDzRsSEExVyJheaKvTyXQWrSgZZBbtqQ3Z4698iRfwe+oUaMwc+ZM7Ny5k6s7aKNNm4Bx4+jyokVAv37itocVChkZNIJ1+jQFvGfO0ADDh5ydVUezXFw4dYHpNkNDKpvu6QkMGUL7Xr2iIFhxluT8edp38mRW+TWplEaDGzak9YYaNaL0IMY+qVgxYP9++oe5cYMC4DNnKA+Y5Uq+gt/27dtDIpGgatWq6NixI7y9vVGzZk3UqFEDhrwGtbiOHaOZoQAwZgwwerS47WFaKzOTgt0TJ4CQEAp6k5NVjzEyopHchg1ptKpuXZ6MxlhumJsDzZvTBtAUjOhoCoQVZ1Pu3qXXYHg4sHw5HefsDDRpkrVx3jDLUenSlGNTrx5VcurUiT7/ebXWXMlX8Hv79m1EREQot7lz5yIuLg4GBgZwcnLC1atX1d1Olhs3bgBdu9IQXu/eVAybsf8IAk3eCQ6m7dSp7MGumRmNQDVsSJunZ1b9XMZY/kmlVLKvWrWs8YlHj7IC4dOnKXVCUZN49Wo6xsWFgmAfH6BpUyrzyhgAwNaWJrTXq0cpEH5+wNatfCouF/IV/Do4OMDBwQGd35sWm5ycjIiICA58xZKQQLV8k5MpeuF1wBlowYhjx2g7fpwq5bzPzIzOnClGmTw8eJUrxgpK+fJAjx60ATRp7tQpOhMTEkJVJqKiaFu1iuY71a5NgXCzZnQ2xsREzGfAROfiAvz9N+UABwRQHb/Zs8VuldbLV/D7/PnzbLm+ZmZmaNiwIRo2bKiWhrE8SE2len/37lGtnr17ebhOR6Wk0Ifm4cO03byper2JCQW7zZrRKFLNmhzsMqYtSpems9edOtHvSUkUDB8/Tl9go6Opfva//1K5VyMjoHFjSvls2ZJGlbnWsA5q2hT4809gwABgzhyqIcmLYHxSvoJfCwsL2NjYwN3dXWWrWrUqJPl85a1cuRILFy5EQkIC3N3dsXz5ctSpU+eztwsICECvXr3QsWNH7N27N1+PXahlZtK632FhtKRRYCAvg6VDFKkMQUEU7J4+TTPPFfT0KGe3WTMaLapbl78XMVZYlClDdYcVJ1kfPsxKWzp2jNImjhyhbfRoOgveogUV92nenBbjYDqif39alWXWLOD776n6Q7NmYrdKa+Ur+L127RrCw8MRERGBsLAwrFmzBs+fP4exsTGqV6+OCxcu5On+duzYAX9/f6xevRpeXl5YunQpWrZsiZiYGJQrV+6jt4uLi8OYMWN0e7R53Dhgzx6abrx3L+DoKHaLmIalpNBI0MGD9F3n/n3V6ytWzBoJataMSykxVlTY2ADffEObIFA6xOHD9OX31CngwQPKeFu/nr741q8PtGlDGXGurjwqXOTNmEEB8LZtNP/n3Dk6HcCyyVfw6+rqCldXV/Tp0wcAIAgCgoKCMHz4cDTLxzeNJUuWYPDgwfDz8wMArF69GgcPHsT69esxYcKEHG+TmZmJPn36YMaMGTh9+jRevnyZn6dSuP3+e1Yt340bKdeXFUlxccA//1DAGxICpKVlXWdsTGe9WrWigLdqVf6QY6yok0iyJtCNGgW8fUsBsCIYjoqi30+dAiZMACpUoEC4XTvg6685V7hIkkjom098PM2kbNMGuHCBS4bkQC1rzUgkErRu3RpbtmzBmjVr8nTb9PR0XLp0CRMnTlTuk0ql8PHxQWho6EdvN3PmTJQrVw4DBw7E6dOnP/kYaWlpSHsvWkj+b4q7TCaDTCbLU3u1heTYMegNHw4JgMwZMyDv1o2WHmLZKPq4MPW1XA5cvizBP/9IcOCAFNeuqUaz9vYCWreWo3VrAY0bCyofZBkZBdxYLVMY+5vlny719+vXr3H//n08ePAA9+/fR5kyZdDpvwRhfX0Kar/+mgr9xMYCQUFSHDokQUiIBPHxEqxeTVUkihUT0Ly5gPbt6T2kbFlxn1de6FJ/54tUCuzaBf2GDSG5fRvyjh2RefRooS2Bpql+VutCi3Xr1kWvXr3ydJtnz54hMzMTlh98M7G0tER0dHSOtzlz5gzWrVuX66WU582bhxkzZmTbf+LECRQrVixP7dUGxR8/RqOxY6EvlyO+aVNccXOj89/sk44ePSp2Ez5JJpPg2rWyOH/eGmFhVnjxIuvNSioV4OKShK++SkDt2omwtX0DiYSC5BMnRGy0FtP2/mbqVVT6OyMjA+fPn8fjx4/x7NkzPHn6FE+ePkNS0jO8S01VObZqVadP1tavWBH44QfAz08P166Vwb//WiEszApJSSbYt0+CffukkEgEODs/R506Cahb9zGsrXNYr1wLFZX+1pTi/v5oNG4cDC9cwINOnXBl+PBCeUow9YP/eXXJdfA7btw4zJw5E8bGxjA1NUX16tXh7u4ONzc3uLu7w9nZGWFhYXj9+rVGGqrw+vVr9OvXD2vXroVFLlczmThxIvz9/ZW/Jycnw87ODk2bNkWZwjY5LDmZvtG9eQO5lxes9++HNc9g+iSZTIajR4+iefPmMDAwELs5Kt68AQ4fpg+hwEAJkpOz3pxKlBDQsqWAdu3kaNVKQJky5gDMATiJ1t7CQJv7m6lfUevvsLAwLFq0CPomJWBY0hJC8TLQs6gBYwcLSB5E4u2dMBgaGWPihPHw9/eHSS7zFxST5gQBCA+X4cABKf75R4rwcAmiosogKqoMNm1yRfXqAjp2lKNTJznc3LQvXipq/a1JEnt7CO3aocLx47Bp2xby4cPFblKeJSUlaeR+cx38Ll26FKNHj4axsTGKFSuGtm3b4vr161i2bBnu3LkDQRAgkUgwa9asPDXAwsICenp6SPygAGliYiKscljn8c6dO4iLi0P79u2V++RyOT0ZfX3ExMSgcuXKKrcxMjKCUQ4BooGBQeF68cjlVL4kKgooXx7SPXsgLVFC7FYVGtrS369e0cqUu3fTLO1377Kus7LKKnXUpIkERkYSAFyvOT+0pb9ZwSjs/S2TyRAcHIwtW7YCAEp4dYe5V1cAQPrTOLw6thpv46+jU+fO+HXJEtjb2+f7serUoW3mTJow+88/NG/6xAng+nUJrl/Xw5w5eqhUCejSBejenY7XpkC4sPd3gWjdGli0CPD3h964cdBzc6OyP4WIpvo418Fv+fLlER4ejpYtW+LZs2f47rvvlJUYUlNTERsbizJlyuQYsH6KoaEhateujeDgYGXuklwuR3BwMIYNG5bteGdnZ1y7dk1l3+TJk/H69WssW7YMdnZ2eXr8QmXaNIqajIzoncraWuwWsVx6+ZK6btcuCnjfL0fm4EAfMJ07UykyXpuEMd0gk8lw4sQJ7NixA7v/9zeSX73Muu5JLOTv3uDlma14cyUQDpUr4/fDh9GiRQu1tsHODvjxR9qePwcOHKA1Ew4fprzhxYtpq1AB6NaNAmEvL+0KhNknjBxJ62dv3kyrqYSF0UIYOi7Xwe/o0aPRvn17eHl5AQC2bt2KBg0aoHr16ihWrBhcXV3z3Qh/f3/0798fnp6eqFOnDpYuXYqUlBRl9YdvvvkGNjY2mDdvnrKc2vtK/lfM8MP9RcquXVmrtqxZQ1/DmVZLTgb27QN27KCA9/28fRcX+iDp2hVaeWqRMaYZGRkZCAkJUQa8L188z3aMoaERUiJDkBb7LwylAn6ZPw8jRoz4ZH6vOpQunVVKLSUFOHQI+N//aGQ4Pp6KCy1ZQgFzt25Az57AV1/x+5dWk0iAP/6gFVIuXgQ6dgRCQwFTU7FbJqpcB7/Dhw9H48aN8c8//+Ds2bNYuXIlxo4dC4lEAkdHR7i7u8PDwwPu7u5o3bp1nhrh6+uLp0+fYurUqUhISICHhweCgoKUk+Di4+Mh1eXhsPBwWrkFAPz96Z2JaaW3b6kcWUAA/Xw/paFaNRo16d6dam4yxnRDZmYmTp06hR07dmDX7v/hedKzbMeYFCuOjh06wNe3B5o1a4Z69RugenVXLFq4EDY2NgXe5uLFKcDt1o3e14KCaAzmn38oVeLXX2lzcKAguFcvoCiPPxVqxsZ0ttjTE7hxA+jXj4b3dTiukgiCIOT1RlWqVEFoaCiKFy+Oq1evIjw8XLldv35d45PevlRycjLMzc3x7Nkz7Z/w9vQpfbW+d4+W7jl4kGrasFyTyWQIDAxEmzZtNJI/lJEBHD1KdcX37qVJbApOTvTB0KMH1xovKJrub6ZdtLW/MzMzcebMGezYsQM7d/8PSU+fZDvG2KQYOrRvB19fX7Ru3TrXk9fE9PYtpUTs3Elntt6fjO/qSkFw795ApUqaeXxt7e9C4cIFWt8+PR2YMoWSvrVcUlISLCws8OrVK5iZmantfvMVRd26dUt52cvLS5kKAdCCF0xNMjOBPn0o8HV0pOFEDny1giBQ6tSWLdQtT59mXVexIgW8PXsC7u58SpAxXSGXy3Hu3DkEBARgx67dePYkMdsxRsYmaNeuLXr6+qJNmzaFrtymiUnWpNyUFMoR3r6dUiRu3AAmT6atfn2gb18606XtY0w6w8uL0iYHDKBlkL28aPk/HaT2SErCn/TqM2sWDSmamNApi1KlxG6RzrtzB9i6lYLe974DomxZwNeXRj28vTngZUxXyOVynD9/Hjt37sT2HTvxJOFxtmMMjYzRpk1r9PT1Rdu2bVGiiFTpKV6c3vd8fWlS7549dAbs+HHg7FnafvqJig707Qu0b19o11ooOvr3p5GblSsp/eHyZeALKocUVjyMqK2CgrJOSfzxBydTiSg5mU7xbdpEK0YqmJhQhYa+fal6DJ+BY0w3CIKAixcvYseOHdi+YycSHj3MdoyBoRFat26Fnr6+aNeuHUyL+ASjkiUBPz/aHj2iM2JbtgBXrlClm/376RhfX4q/6tblQQLRLF5MAfDFizQ0f+YMVZHSIRz8aqP4eIqoBAH4/nv6dsYKVGYmEBxMAe+ePZTnBtD8gGbNqEs6ddL5CbOM6QxBEPDvv/9i586d2BawA48e3M92jIGBIVq0bIGevr7o0KGDWnMUC5Py5Wlutr8/pUIozpbdv09jOX/8AVStSkFwv35UPYIVICMjGtGpVQv4919g1Cjg99/FblWB4uBX26Sn0+yopCT6x1y6VOwW6ZS7d4H16ynoffAga7+LC71R9+0LiDDxmjEmAkEQcPnyZWXA+yD+XrZj9PT10bx5c/Tq2RMdOnRQlt5kxNUVmDuXKnWeOEHvrf/7H3DzJjBpEuUHN2sGDBxIAwqcFlFAKlakbyRt2wKrVlGSdp8+YreqwHDwq23GjKEZmSVL0hJg/E6gcW/f0pvxunVASEjW/lKlKIe3f3+uZcmYrhAEAREREcqA917s3WzH6Onro1mzZujp64tOnTqhFM/H+CzFWbNmzSjddPduCoRPngSOHaOtVCkaYBg4kCYLMw1r3Zq+fcyaBXz3HeDhoTN1ODn41SY7dgDLl9Plv/7SXK0YBoBy0daupQkar17RPokEaN6c3nw7dtS5NCjGdJIgCLh27Zoy4I29czvbMVI9PXzd9Gv07EkBr9aXydRipqZZ+cGxscCGDbQ9eEAfgcuXA7Vr0/tw796AubnYLS7Cpk2jRS+OHaNVl8LCdCKfj4NfbREdDQwaRJcnTgTatRO3PUXUmzc0EWPNGnqNK1SsSG/EAwbQZcZY0Xfjxg1lwHv7Zky266VSKRo1boJePX3RpUsXWFhYiNDKoq1SJZrbPW0aFTdat47qB1+6RNuYMXQG7rvv6AwcUzM9PRoBqlkTiIkBBg+m2nVF/FQnB7/a4N07Kgr75g3QpEmhKDxd2Ny9a45hw6TYvh1QrMFiYEDVGgYPBr7+WqcXu2FMZ0RFRSkD3pvRUdmul0gkaNiosTLgLVeunAit1D16ekCrVrQ9fUrpqGvXAlFRFBCvW0epEIMGSVG6NIcualW2LJ15btKEfvr4ZA3GFVH8H6QNJk4EIiIACwv6BsYLWajF27c0oXXlSj2EhTVR7nd0pFGE/v0B/lxjrOiLiYlRBrzRkTeyXS+RSFCvfgP06umLrl27wsrKSoRWMoWyZakAwciRVCv4jz9oaeWICGD4cD0YGbXE8eNSDBtGaapMDerXB+bMAcaPB0aMABo0AJydxW6VxnCUJbZDh7IqOmzcCFhbi9maIuH2bWD1asohe/4cAKTQ15ejc2fghx+kaNKER3kZK+pu376tDHhvXLua4zHe9eorA97y5csXcAvZ50gkFIM1aAAsW0ZTYf74Q0BUlL5yNNjbG/jxR6BbN54f/sXGjAGOHKE6n717Uy5wEZ34wsGvmBITKckUAIYP19llBtUhMxM4eJBKFR4+nLW/YkVg8OBM2NoeQe/ePjAw4KiXsaLq7t27yoD3WkR4jsfU8aqLXj190a1bN9ja2hZsA1m+lS5NA5JDhmRg0aILiIiohz17pAgNpRht5EiaIDdkiE4uWKYeUimweTPg5kYzwidNAhYtErtVGsGRgFjkcgp8nzyh1dsWLBC7RYXSixf02qxShaozHD5MowVt2gD//EPLEY8bJ0fJkuliN5UxpgFxcXHYs2cPvvKqi8qVK2PixInZAl/Pr+pg8eLFuHfvHi6cD8XIkSM58C2kJBLA1TUJW7ZkIj6e6gfb2VFp/AULgMqVqV5wcDCtE8XyqHx5KnYP0EpwR46I2x4N4ZFfsSxfTksYGxvTzEo+X5Mn16/Tn3DLFiA1lfaVLk05+j/8oFolTi4Xp42MMc2Ij4/Hrl27sC1gBy7/G5bjMTVre6L3fyO89jwUWCRZWdHg5PjxQGAgsGIFVYzYt4+2atWAYcNoFbkSJcRubSHSoQPlkvz+O/DNN8DVq0VuggwHv2KIiADGjaPLixfTyC/7LEVqw9KltFKQgpsb8NNPVA6nWDHRmscY06AHDx5g165d2B6wA2EXL+R4jJtHTfTu6Yvu3bvDwcGhgFvIxKKvT/Fahw5UHWLFClpAIzKSYriJEyklYvhwTonItUWLaNWnyEjg22/pVGoRKn/GaQ8FLTWVorT0dHqlDhkidou03ps3NMrr5ESpDSdOUFmcrl1pdaDwcHpj48CXsaLl0aNH+O233+Bdrz7s7Ozg7++fLfB1reGGvn37IjIyEhFXLmP8+PEc+OowFxdaQe7hQxooqVyZFjFasoQud+9OFSQ4JeIzTEyoKL6REY06rVwpdovUioPfgjZmDH01tbamqapF6JuUut27B4wdC9ja0sjunTu06vO4ccDdu7Q8ZqNG/CdkrChJSEjAihUrUL9BQ9ja2mLEiBE4H3pO5Zhq1Wtg9uzZiImJwZVL/6Jbt25wdHQUqcVMG5mb0wS5mzeBAwdoWWW5nD43GjQAvLwo41AmE7ulWqxGjawJb2PGUL5hEcFpDwXp2DFg1Sq6vHkz1fVl2Vy6RK+3Xbso1QEAqlalN7JvvuHcLcaKmsTERPz999/YHrADZ06fgpDDsJyTSzVlSoOLi4tyv4yjF/YJUikVUmrbFrh2jUqmbdlCK3z27k2DKSNGUO13MzOxW6uFhg6l+UkHD9Ik/dBQWiGqkOPgt6AkJ9O5eYD+mXx8xG2PlpHLqeSxIs1IoVkzKnbeujXX5mWsKHn69Kky4D196iTkOcxMdazqhD69eqJ79+5wdXUVoZWsKKlRA/jzT2DuXKoF//vvwIMHdIZx1iwKgEeMoLON7D8SCS215+pKI1MLFtAsw0KOw4mCMnYsEB8PODgA8+eL3RqtkZZGVVVq1ADataPAV18f6NuXcnmPHaNv7Bz4Mlb4JSUl4c8//8TXzXxgZW2NH374ASdDTqgEvpUqO2Ly5Mm4evUqbkZHYfr06Rz4MrUqVw6YOhWIi6Ng2MWFxqcWLaJKQYoCB+w/1tY08QYAZswoEn8cHvktCEeOAGvW0OX16/m8PeiNZs0amoTw+DHtMzUFvv+e8nvt7MRtH2NMPZ4/f469e/ciYMcOBAcHQ67IZXpPxUoO6NOrJ3r06AE3NzdIOJGfFQBjYzoh6+eneubxr79oa90amDABaNiQ55agd2/KRdy3j9IfLlwo1OkPHPxq2qtXVHwWoDorjRuL2x6RJSYCv/1Gp5tevqR9Nja0Os/gwTRJgTFWuL18+RL79u3D9oAAHDt2DJkZGdmOsatorwx4PTw8OOBlonk/L/jff7PmnBw6RFvduhQEt2+vw2chJRLKFTl9mlZ/mzePhs8LKQ5+NW3MGOD+faqxMm+e2K0RTWwssHAhsGED8O4d7XN2puLkvXsDhobito8xpj4eNWvhXlxstv02dhXQu6cvevTogdq1a3PAy7SOpydV+Jozh8rwr18PnD9Pq8a5uNAEuT59CvWgZ/5ZWVER5d69KUm6Y0fA3V3sVuWLrn6HKRhBQZRQJJFQ1Fe8uNgtKnBRUZQ/VaUKFbp4945KzOzZA9y4QWdPOPBlrGh5v86utY0tRo8ejQsXLuD+vTgsWLAAnp6eHPgyrVa5Mp2hvHePFskwN6fPMz8/wNGRyt6+fSt2K0XQsyfQuTOQkUEf4OnpYrcoXzj41ZRXr+g8PkBJrA0bitueAnblCtCtG00Q/esvKlnWogXlU4WG0rdonT19xFgRN2f2LIwfPx7nzp3Dg/h7WLRoEerUqcMBLyt0LC2pOkR8PPDLL/R7fDwtm1ypEqVIvHkjdisLkERCI1llytCs9LlzxW5RvnD4oSn+/lRDxdGx0P5z5EdoKOVN1aoF/O9/tIpOp05UU/HwYUp55s8/lhOJRIK9e/fm+viNGzeiZMmSH70+Li4OEokE4eHhX9w2Tfnccygo6enpcHR0xLlz5z5/8H8iIyNha2uLlJSUbNd5e3tj/vz58Pb2hpS/5bIiwMyMUh5iY+nMf4UKNIdl7FigYkVg5syseSxFnqVl1opvc+bQaFchw+9KmhASQolCinQHHVh39/RpoHlzoF49IDCQRnV796ai4nv2UB4V000JCQkYMWIEHB0dYWxsDEtLS9SvXx+rVq1Camqq8rjHjx+jdevWub5fX19f3Lx586PX29nZ4fHjx6hevfoXtV+TPnwO06dPh4eHh1ruWxAErF27Ft7e3jAzM0OJEiXg6uqKESNG4Pbt2yrHrl69GpUqVUK9evVyff/VqlVD3bp1sWTJErW0l7HCwMSESvXfukUf81WqAM+fA9OmURA8dSr9XuT16AF07UrpD999l7UiVSHBwa+6pacDQ4bQ5SFDaB3FIiwkBPj6a1pm+NgxqtE7cCAQEwNs3QpocdzBCsDdu3dRs2ZNHDlyBHPnzsWVK1cQGhqKcePG4cCBAzh27JjyWCsrKxgZGeX6vk1MTFCuXLmPXq+npwcrKyvo62vnvF6ZTPbZ55BfgiCgd+/e+Omnn9CmTRscOXIEkZGRWLduHYyNjTF79myVY1esWIGBikV48sDPzw+rVq1CRg7VHBgrygwNKf83KoomyFWvTiU8Z80C7O1pHYhnz8RupQZJJDQEbm5OJTL++EPsFuWNoINevXolABCePXum/jufM0cQAEGwtBSEFy/Uf/9aQC4XhOBgQWjUiJ4qIAgGBoLw/feCEBsrduuyS09PF/bu3Sukp6eL3RSd07JlS8HW1lZ48+ZNjtfL5XLlZQDCnj17BEEQhNjYWAGA8L///U9o0qSJYGJiIri5uQnnzp1THr9hwwbB3Nw8230q+vvmzZsCAOHKlSuCIAjCiRMnBABCUFCQ4OHhIRgbGwtNmzYVEhMThcDAQMHZ2VkwNTUVevXqJaSkpCjvr3HjxsLQoUOFoUOHCmZmZkKZMmWEyZMnf7TtCubm5sKGDRtUnk9AQIDQqFEjwcjISNiwYYPKc9iwYYMAQGXbsGGD4OfnJ7Rt2zbbcyxbtqzw559/5vh33b59uwBA2Ldv32f/7mFhYYJUKhWSk5OV+xTt3b59u+Dt7S0YGRkJrq6uQkhIiMr9pKWlCUZGRsKxY8dyfJyCwK9v3aKt/Z2ZKQi7dwuCm1vW52Lx4oIwfrwgPHkidus0aMUKerJmZoLw+LHa7/7Zs2cCAOHVq1dqvV8e+VWnu3fpax9AqzdoQS6fup08CTRpQssOnzpF336HDAFu36YSgPb2YreQaYukpCQcOXIEQ4cORfGPVDr53ASoSZMmYcyYMQgPD0fVqlXRq1evLx5lnD59OlasWIFz587h/v376NGjB5YuXYpt27bh4MGDOHLkCJYrVjP6z6ZNm6Cvr4+LFy9i2bJlWLJkCf788888P/aECRMwYsQIREVFoWXLlirX+fr6YvTo0XB1dcXjx4/x+PFj+Pr6YtCgQQgKCsJjxWowAA4cOIDU1FT4+vrm+Djbt2+Hk5MTOnTokOP17//dT58+japVq8LU1DTbcWPHjsXo0aNx5coVeHt7o3379khKSlJeb2hoCA8PD5w+fTpPfwfGihqplLIArlyhVL+aNYGUFJokV6kS8PPPwHsvnaLjhx8orzE5meY6FRIc/KqLIFAi0Lt3FBn26iV2i9Tq3DnAx4cCX0XQO2wYcOcOlYOpUEHsFjJtc/v2bQiCACcnJ5X9FhYWKFGiBEqUKIHx48d/8j7GjBmDtm3bomrVqpgxYwbu3buXLV81r2bPno369eujZs2aGDhwIE6ePIlVq1ahZs2aaNiwIbp164YTJ06o3MbOzg6//vornJyc0KdPHwwfPhy//vprnh975MiR6NKlCypVqgRra2uV60xMTFCiRAno6+vDysoKVlZWMDExQb169eDk5IS//vpLeeyGDRvQvXt3lPjIapE3b97M9ncfOXKk8u9ua2ur3H/v3j2UL18+x/sZNmwYunbtChcXF6xatQrm5uZYt26dyjHly5fHvXv38vR3YKyokkppkvelS8D+/UDt2hQEz5tHQfDUqUVsYpyeHo18SaXA9u3A0aNityhXtCb4XblyJezt7WFsbAwvLy9cvHjxo8euXbsWDRs2RKlSpVCqVCn4+Ph88vgC8b//UV1fQ0OKBotISYOLF4FWrYD69YHgYCrsPWQIBb3LlwPvfYYylisXL15EeHg4XF1dkZaW9slj3dzclJcVweKTJ0++6PHfv09LS0sUK1ZMpS6tpaVltseoW7euymipt7c3bt26hcw8TvLwzOfMz0GDBmHDhg0AgMTERBw6dAjffvttnu5j0qRJCA8Px9SpU/HmvdpMb9++hbGxcY638fb2Vl7W19eHp6cnoqKiVI4xMTFRmbjIGKMQoH17qnS0bx+tBfH6dVZO8MyZVBG1SKhdm0bDAODHH7NWstJiWhH87tixA/7+/pg2bRouX74Md3d3tGzZ8qMfciEhIejVqxdOnDiB0NBQ2NnZoUWLFnj48GEBt/w/ycnAiBF0ecIEoGpVcdqhRlevAh060IIUhw/TRLbBg2mG6++/c9DLPs/R0RESiQQxMTEq+x0cHODo6AgTE5PP3ofBe8soKYJPuVz+Re368D4NPliqSSKR5PkxJBIJBEFQ2SeTybId97H0j8/55ptvcPfuXYSGhmLLli2oVKkSGn6idniVKlWy/d3Lli0LR0fHbBPsLCws8OLFi3y1CwCeP3+OsmXL5vv2jBVlEgl9ll6+TGNk1atT0DttGuDgACxYABSJ746zZgHW1pQDOX++2K35LK0IfpcsWYLBgwfDz88P1apVw+rVq1GsWDGsX78+x+O3bt2KH3/8ER4eHnB2dsaff/4JuVyO4ODgAm75f6ZNAx49oiVhJk4Upw1qcvMmZWx4eAD//ENnMvr3p+oNa9ZQKRfGcqNMmTJo3rw5VqxYkWMt2MLkwoULKr+fP38eVapUgZ6eHgAKLN/Pyb1161a+RkMNDQ1zHE0uU6YMOnXqhA0bNmDjxo3w8/P75P306tULMTEx2Ldv32cfs2bNmoiOjs4WvAP0PBUyMjJw6dIluLi4qBxz/fp11KxZ87OPw5guk0qBLl2AiAhgxw7A2ZlKoo0fT6HDypWFdrE0YmYGLF1Kl+fNo5EyLSZ6DaD09HRcunQJE98LGqVSKXx8fBAaGpqr+0hNTYVMJkPp0qVzvD4tLU3l9GpycjIAGpnJaXQmT65cgf5vv0ECIOO33yDo6QFfep8iuH8fmDNHD5s2SZCZSSNs3bvLMXVqJhSpg4XwaQHIGoH74r5mebZs2TI0adIEtWvXxpQpU1CjRg1IpVL8+++/iI6ORs2aNVX6JSMjQ+V1+eHl949RBIkf9uv7x71/Hx/+DiDH+8jMzIQgCMp9giAgPj4eI0eOxKBBg3DlyhUsX74cCxYsUB7TpEkTLF++HJ6enpDL5fj5559hYGCAzMzMjz6fnB7f1tYWsbGxCAsLg62tLUxNTZXl3wYMGIBOnTohMzMTvXv3/uT/c9euXdGlSxf07NkT48aNQ4sWLVCuXDnEx8cjICAAenp6yts3aNAAb968QXh4uLImsuK6lStXolKlSnB2dsZvv/2GFy9eoF+/fsrr4+Li8PDhQzRu3Fi01xe/vnVLUejvzp1pNHjrVglmz9ZDXJwEw4YBixYJmDw5E336CPjve3Xh0qkT9Fq0gPTIEciHDEFmYOAXp4Bqqp9FD36fPXuGzMxMWFpaquy3tLREdHR0ru5j/PjxKF++PHx8fHK8ft68eZgxY0a2/SdOnECxL1mAQi5Ho/HjUUoux4MGDXBJJqMVHgqR5GRD7NpVFYcO2SMjg04EeHomoHfvKDg4JOPOHcrvLQqOFpJE/KJm3rx52L17N0aPHo2kpCTo6+vDzs4OrVu3hre3NwLfe81cunQJBgYGSExMBACcOXMGjx49AgBlnur58+eRkpKCiIgIyGQyldu/T1GBQHEf165dAwAcOXJEOVEsp/u4desWkpOTlfuSkpLQsGFDxMTEwMvLC1KpFK1bt0b58uWVx7Rq1Qo3b95E48aNUbp0aQwcOBAXLlxAREQEAgMDc3w+OT1+sWLF4ObmhqZNmyIlJQXDhw9Hs2bNAFAQbm5ujgoVKiA8PPyzK9f17dsXlpaWCAgIwIIFC5CRkYEyZcrAzc0NM2bMUHnOderUwZw5c9CvXz8AULa3W7dumDRpEmJjY2FtbY3x48erzK/YvXs3PDw8cOPGDdy4ceOT7dE0fn3rlqLQ3xYWwMKFEhw9WhG7djkhLs4YgwbpY/r01+jbNwpeXo8L3fSh4p07o+mJE9ALDsblCRPwsHHjL7o/Tc0nkAg5nesqQI8ePYKNjQ3OnTunMrli3LhxOHnyZLbTjR+aP38+FixYgJCQEJWJLO/LaeRXsfpTmTJl8t12yebN0B80CIKpKTKuXQM+MmNaG715AyxbJsWSJVK8fk2vrsaN5Zg1S466dUX9l1A7mUyGo0ePonnz5tnyO1nRo+7+9vHxgbu7OxYvXqyG1uXfmzdvYG9vj7Vr16Jz585qve+rV6+iTZs2iI6ORokSJRAXF4eqVavi4sWLH11xLj09HdWqVcPmzZvztDKcuvHrW7cU1f5OTQVWrZJi4UIpnj+nz2QvLznmzJGjUaPC9ZksnTMHejNmQLCxQcaNG1+0ym1SUhKsra3x6tUrmJmZqa2Noo/8WlhYQE9PTznSoJCYmAgrK6tP3nbRokWYP38+jh079tHAFwCMjIxyXDnKwMAg/y+e1FSqWQJAMmUKDApJMmx6OrB2LeWmK/7kNWtSfnrz5lJIJFqRBq4RX9TfrNBRV39LJBJIpVLR/nfkcjmePXuGxYsXo2TJkujSpYvaV62rXbs2fvnlFzx48AA1atRQPtdP/Q3v3buHn3/+GY2/cGRHXfj1rVuKWn+bm9N8+SFDgEWLaKmACxek8PGRonVrSqN1dxe7lbk0YQKwcSMk9+7BYPlyYPLkfN+VpvpY9EjH0NAQtWvXVpmsppi89v5I8IcWLFiAWbNmISgoKN/lg77I4sU0yc3eHhg+vOAfP48EgZLsXVyoIkliIiXZb99OKxO2aFFkqrMxVqTEx8fD0tIS27Ztw/r16zW2XPOAAQNQo0aNXB/v6OiI77//XiNtYUxXmZvT4NSdO1Q1TF8fOHSIBqn69gXi4sRuYS4YG1O0DtDIWkKCuO3JgejBLwD4+/tj7dq12LRpE6KiojBkyBCkpKQoZzR/8803KhPifvnlF0yZMgXr16+Hvb09EhISkJCQoFK7UqMeP6ZlWwDq2I/UyNQWJ09SybKePWkROktLmlkaGUn7pFrxX8CYdgoJCcFSxSxmEdjb20MQBNy/f1+Z/1tQj/mxlAfGmGZZWdHndFQU4OtLA1hbtwJOTsCYMVQpQqv17AnUqUMrfEybJnZrstGKsMfX1xeLFi3C1KlT4eHhgfDwcAQFBSknwcXHx6uUEVq1ahXS09PRrVs3WFtbK7dFixYVTIOnTqUO9fICevQomMfMh8hImlHapAkV2i5RApgxg8rw/fgjrcfBGGOMMe3k6AgEBNAZ2mbNKHVx8WLav3ixFq8nIZFQAwHgzz+B69fFbc8HtCL4BWgZzXv37iEtLQ0XLlyAl5eX8rqQkBBs3LhR+XtcXBwEQci2TZ8+XfMNvXYNUNQfXrJEK3MFHj8GvvsOqFGDavXq6VGwe/s2xe0fWRGVMcYYY1qodm1aOfjQIfpsf/GCRoCdnWlE+AvX/tGMBg2ouLFcDowdK3ZrVGhN8FtojB1LHdmtGyDiDOecpKZSrlCVKjSpTS6neoI3btDpkw+qyTHGGGOskJBIgFatgCtXaAzOxga4d49ygb28gP+qO2qXX34BDAyAoCDgyBGxW6PEwW9eHD5Mm4GBVi3fJ5cDf/1Fqyq/n5Fx+jTw999QLlLBGGOMscJNTw/w86MVWefMAUxNKS2iUSMal9Oq2vyOjsDQoXR5zBgghxUsxcDBb25lZlLHAVQuoXJlcdvzn1OnKKf8m2+Ahw9p+eGAACA0lM44MMYYY6zoKVYM+PlnWkn4++9p8vr//kdVncaMAV6+FLuF/5kyBShZktJG30thFRMHv7m1YQMlbJcq9UU169Tl7l36hte4MXDpEn3zmz8fiI6mmaFamIrMGGOMMTWztARWrwYiIoCWLQGZLGtS3MqVwH8ru4undGkKgAH6WVCVuT6Bg9/cePMmq+OmTqWOFMnr1/RNz8WFvuFJpcAPP9BktvHjtb7qGmOMMcY0oHp1Sq09dAhwdQWSkuhEtYcHcOyYyI0bOhRwcKAZ+QVVmesTOPjNjeXLqUhz5cpUNkEEcjmdLahalWpHp6cDPj70TW/VKqBcOVGaxRhjjDEt0qoVEB4O/P47UKYMTXpv3hzo2JEGykRhZJS1PsKiRRSZi4iD389JSaGSZgAwfbooxXHPnaMJbH5+FIM7OgL79tHEyerVC7w5jDHGGNNi+vq0VPKtW8CIEfT7/v1AtWpUtOrVKxEa1bUrLVWXkgKIuHAQwMHv5/3xB/DsGY369uxZoA/96BGVMKlfn2ZympoCCxZQ6nGHDpzXyxhjjLGPK1WK4syrV2lEWCajgVcnJzqbXKD1gSWSrDlTv/0m6ow8Dn4/5e1bYOFCuvzzz/TVqQCkp1OQ6+RExaslEuDbb+kb3NixdPaAMcYYYyw3XFwoF/jgQUqfTEyks8mKwbUC06kTJSQnJwMrVhTgA6vi4PdT1q2jPIMKFWgItgAEBdHqLePH0zw7Ly/g4kVqCi9SwRhjjLH8atOGKo4tWECrvZ4/T+VSBw8Gnj4tgAZIpcCkSXT5119pFr8IOPj9mPT0rOTsCRM0nusbG0vJ6K1bU+HqcuWoutq5c4Cnp0YfmjHGGGM6wtCQziLHxNC4niAAf/5JI8LLlxdAabQePejBnj+nGfsi4OD3YzZtAh48AMqXp3MDGvLuHTBzJiWh799PmRX+/hQADxhAX5IYY4wxxtSpfHlaHfbMGSqH9vIl8NNPNOB27pwGH1hPj1JJASpInJqqwQfLGYdWOcnIoHpiAH090lDx3EOHqFrDtGkUBH/9NZUuW7wYMDfXyEMyxhhjjCkp8n5XraIJchERtO/bb4EnTzT0oL17A/b29ABr12roQT6Og9+cbNtGeQhlywLffaf2u4+LAzp3ptybO3fo29eOHVSEulo1tT8cY4wxxthH6enRglk3bwIDB9K+DRto4v3vvwOZmWp+QAMDYOJEurxgAY0AFiAOfj+UmQnMmUOXR4+mxbPVJD0dmDuXAty9eynFYcwYWpK4Rw8uXcYYY4wx8VhYUP5vaCiV5H35khZnq1OHJt+rVf/+gK0t1XXduFHNd/5pHPx+aPdu+upTurRaV3M7eZJyaiZNogpqjRvTCiwLF1L9XsYYY4wxbVC3LhAWRtXIzM2By5dp39ChaizPa2QEjBtHl+fPpyLEBYSD3/fJ5cDs2XR55Ei1RKVPn9LEtSZNgKgoquLw11/AiRNU6o4xxhhjTNvo6VGwe/Mm0K8fVYX4/XfA2RnYvp1+/2KDBlEd13v3KDgqIBz8vm//flo+zcwMGD78i+5KLqdTB05OVDhCIqF8muhoKi3CKQ6MMcYY03blygGbNwPHj1NMk5hI89VatKDFt76IiQnlfwKUF6r25OKccfD7PkW9uaFDgZIl8303N24ADRtS0egXLyjdITQ0ayYlY4wxxlhh0rQpVYKYPZuKYB07RhWrZs4E0tK+4I5/+IGCozt3gOBgtbX3Uzj4VXj0iHoSyJrqmEdv39Ky1TVrUo28EiVoAZOwMFqpjTHGGGOssDIyorlL168DrVrRRP5p02iQ7/TpfN5piRJAr150efNmdTX1kzj4Vdi2jXIV6tcHKlfO882DgwE3NyoUIZPRam2RkZQ6rK+v/uYyxhhjjImhcmUgMBAICKCU3ehooFGjrDPeefbNN/Rzz54CWfKYg18FxbcNRQfk0rNnVK3Dxwe4fZtq9v79N5Uys7NTfzMZY4wxxsQmkQC+vjSZf/Bg2vfnnzQhLiAgjxPi6tShJY9TUymI0jAOfgFKYrl2jRa87t49VzcRBGDrVsDFheJmiYRShSMjaQELxhhjjLGirlQpYM0a4NQpiomePKEshrZtqYhDrkgkVFICKJCqDxz8Almjvh065GpG2r171Kl9+9LIb40alOOrqIfHGGOMMaZLGjYErlyhCXCGhsChQ1TSdfnyXBZx6NuXfh4/Dty/r9G2cvCbkUH5vkDWt46PyMykTnR1pU41NKRZj5cuUfFnxhhjjDFdZWQETJlCJ9Tr1wdSUoCffqLAODLyMze2t6fEYcWpdQ3i4PfYMSAhgdb0a9Xqo4dFRlLn/fQTdWaDBtS5kybREtWMMcYYY4zyfk+dAlaupGIOiuWSZ86kChEfpZh39ddfalpFI2cc/CpyS3r2pKHcD8hkNLqrqNVrakornJw8SZ3LGGOMMcZUSaXAjz/S4GHbtlll0WrXphKwOerWjYoIR0bSmsqaapvG7rkweP2aymoAOVZ5uHKFJiBOmUJBcLt2tIDFkCHUqYwxxhhj7OPs7IB//qElkcuWpRrBdesCEybQ+ggqzM2pViyg0YlvOh3CSf75h/7yTk6Ap6dyf1oaLVbx1VdAeDhQujSln+zfz+XLGGOMMcbyQiKhE+yRkVQJQi4HfvmFUiHOnv3gYMX8q23baORRA3Q6+JXu3EkXvvmGegbAhQtArVq0WEVmJlU+i4ykdaz/O4QxxhhjjOWRhQXFtHv3AtbWQEwMzacaOZLmUwEAWrQAypUDnj6F5MQJjbRDt4PfM2foQt++ePcOGDcOqFePgt1y5YDdu4GdO2n1EsYYY4wx9uU6dqQ0Uj8/mte2bBmtknvyJKiKQO/eAADpjh0aeXytCX5XrlwJe3t7GBsbw8vLCxcvXvzk8bt27YKzszOMjY1Ro0YNBAYG5u+BmzTBhccVULMmsHAhDcX36UMBcNeu+btLxhhjjDH2caVKAevXA0FBlFJ69y7QpAkwYgSQ0q0/AEBy6JBGHlsrgt8dO3bA398f06ZNw+XLl+Hu7o6WLVviyZMnOR5/7tw59OrVCwMHDsSVK1fQqVMndOrUCdevX8/T46bBABOLLUO9erQutZUVsG8fsGULUKaMOp4ZY4wxxhj7mJYtaRLcoEH0+2+/AR4D3HHGvi8kn6yLln9aEfwuWbIEgwcPhp+fH6pVq4bVq1ejWLFiWL9+fY7HL1u2DK1atcLYsWPh4uKCWbNmoVatWlixYkWeHrcRTmN+oBvkchphv36dFnljjDHGGGMFw8wMWLuWRoFtbYHbtyVodG8zJmKORh5PXyP3mgfp6em4dOkSJk6cqNwnlUrh4+OD0NDQHG8TGhoKf39/lX0tW7bE3r17czw+LS0NaWlpyt+Tk5MBANFwQblyAlasyESnTlRMWUMTC5mIZP91qow7Vydwf+sW7m/dwv1dtH39NZWZHTtWDxs3SvE7hgGYpPbHET34ffbsGTIzM2H5wawyS0tLREdH53ibhISEHI9PSEjI8fh58+ZhxowZ2fY3drqBgZNewtAwHflNGWaFx9GjR8VuAitA3N+6hftbt3B/F22dOgG2tuWwZl45PMlU//2LHvwWhIkTJ6qMFCcnJ8POzg4Bx+xQxtLzE7dkRYFMJsPRo0fRvHlzGPBa1EUe97du4f7WLdzfuqNNG6Cfy1E49VH/fYse/FpYWEBPTw+JiYkq+xMTE2FlZZXjbaysrPJ0vJGREYyMjLLtNzAx4RePDjEwMOD+1iHc37qF+1u3cH/rhjItvTRyv6JPeDM0NETt2rURHBys3CeXyxEcHAxvb+8cb+Pt7a1yPECnQD52PGOMMcYYY4AWjPwCgL+/P/r37w9PT0/UqVMHS5cuRUpKCvz8/AAA33zzDWxsbDBv3jwAwIgRI9C4cWMsXrwYbdu2RUBAAP7991+sWbNGzKfBGGOMMca0nFYEv76+vnj69CmmTp2KhIQEeHh4ICgoSDmpLT4+HlJp1iB1vXr1sG3bNkyePBk///wzqlSpgr1796J69epiPQXGGGOMMVYIaEXwCwDDhg3DsGHDcrwuJCQk277u3buje/fuGm4VY4wxxhgrSkTP+WWMMcYYY6ygcPDLGGOMMcZ0Bge/jDHGGGNMZ2hNzm9BEgRayvj169dcJ1AHyGQypKamIjk5mftbB3B/6xbub93C/a1bXr9+DSArblMXnQx+k5KSAACVKlUSuSWMMcYYY+xTkpKSYG5urrb708ngt3Tp0gCohJo6/5hMOymWs75//z7MzMzEbg7TMO5v3cL9rVu4v3XLq1evUKFCBWXcpi46Gfwqagabm5vzi0eHmJmZcX/rEO5v3cL9rVu4v3XL+2s9qOX+1HpvjDHGGGOMaTEOfhljjDHGmM7QyeDXyMgI06ZNg5GRkdhNYQWA+1u3cH/rFu5v3cL9rVs01d8SQd31IxhjjDHGGNNSOjnyyxhjjDHGdBMHv4wxxhhjTGdw8MsYY4wxxnQGB7+MMcYYY0xnFNngd+XKlbC3t4exsTG8vLxw8eLFTx6/a9cuODs7w9jYGDVq1EBgYGABtZSpQ176e+3atWjYsCFKlSqFUqVKwcfH57P/H0y75PX1rRAQEACJRIJOnTpptoFMrfLa3y9fvsTQoUNhbW0NIyMjVK1ald/TC5G89vfSpUvh5OQEExMT2NnZYdSoUXj37l0BtZZ9iVOnTqF9+/YoX748JBIJ9u7d+9nbhISEoFatWjAyMoKjoyM2btyY9wcWiqCAgADB0NBQWL9+vXDjxg1h8ODBQsmSJYXExMQcjz979qygp6cnLFiwQIiMjBQmT54sGBgYCNeuXSvglrP8yGt/9+7dW1i5cqVw5coVISoqShgwYIBgbm4uPHjwoIBbzvIjr/2tEBsbK9jY2AgNGzYUOnbsWDCNZV8sr/2dlpYmeHp6Cm3atBHOnDkjxMbGCiEhIUJ4eHgBt5zlR177e+vWrYKRkZGwdetWITY2Vjh8+LBgbW0tjBo1qoBbzvIjMDBQmDRpkvD3338LAIQ9e/Z88vi7d+8KxYoVE/z9/YXIyEhh+fLlgp6enhAUFJSnxy2SwW+dOnWEoUOHKn/PzMwUypcvL8ybNy/H43v06CG0bdtWZZ+Xl5fw/fffa7SdTD3y2t8fysjIEExNTYVNmzZpqolMjfLT3xkZGUK9evWEP//8U+jfvz8Hv4VIXvt71apVgoODg5Cenl5QTWRqlNf+Hjp0qPD111+r7PP39xfq16+v0XYy9ctN8Dtu3DjB1dVVZZ+vr6/QsmXLPD1WkUt7SE9Px6VLl+Dj46PcJ5VK4ePjg9DQ0BxvExoaqnI8ALRs2fKjxzPtkZ/+/lBqaipkMhlKly6tqWYyNclvf8+cORPlypXDwIEDC6KZTE3y09/79++Ht7c3hg4dCktLS1SvXh1z585FZmZmQTWb5VN++rtevXq4dOmSMjXi7t27CAwMRJs2bQqkzaxgqSte01dno7TBs2fPkJmZCUtLS5X9lpaWiI6OzvE2CQkJOR6fkJCgsXYy9chPf39o/PjxKF++fLYXFNM++envM2fOYN26dQgPDy+AFjJ1yk9/3717F8ePH0efPn0QGBiI27dv48cff4RMJsO0adMKotksn/LT371798azZ8/QoEEDCIKAjIwM/PDDD/j5558LosmsgH0sXktOTsbbt29hYmKSq/spciO/jOXF/PnzERAQgD179sDY2Fjs5jA1e/36Nfr164e1a9fCwsJC7OawAiCXy1GuXDmsWbMGtWvXhq+vLyZNmoTVq1eL3TSmASEhIZg7dy5+//13XL58GX///TcOHjyIWbNmid00psWK3MivhYUF9PT0kJiYqLI/MTERVlZWOd7GysoqT8cz7ZGf/lZYtGgR5s+fj2PHjsHNzU2TzWRqktf+vnPnDuLi4tC+fXvlPrlcDgDQ19dHTEwMKleurNlGs3zLz+vb2toaBgYG0NPTU+5zcXFBQkIC0tPTYWhoqNE2s/zLT39PmTIF/fr1w6BBgwAANWrUQEpKCr777jtMmjQJUimP8RUlH4vXzMzMcj3qCxTBkV9DQ0PUrl0bwcHByn1yuRzBwcHw9vbO8Tbe3t4qxwPA0aNHP3o80x756W8AWLBgAWbNmoWgoCB4enoWRFOZGuS1v52dnXHt2jWEh4crtw4dOqBp06YIDw+HnZ1dQTaf5VF+Xt/169fH7du3lV9yAODmzZuwtrbmwFfL5ae/U1NTswW4ii8+NIeKFSVqi9fyNhevcAgICBCMjIyEjRs3CpGRkcJ3330nlCxZUkhISBAEQRD69esnTJgwQXn82bNnBX19fWHRokVCVFSUMG3aNC51Vojktb/nz58vGBoaCrt37xYeP36s3F6/fi3WU2B5kNf+/hBXeyhc8trf8fHxgqmpqTBs2DAhJiZGOHDggFCuXDlh9uzZYj0Flgd57e9p06YJpqamwvbt24W7d+8KR44cESpXriz06NFDrKfA8uD169fClStXhCtXrggAhCVLlghXrlwR7t27JwiCIEyYMEHo16+f8nhFqbOxY8cKUVFRwsqVK7nU2fuWL18uVKhQQTA0NBTq1KkjnD9/Xnld48aNhf79+6scv3PnTqFq1aqCoaGh4OrqKhw8eLCAW8y+RF76u2LFigKAbNu0adMKvuEsX/L6+n4fB7+FT177+9y5c4KXl5dgZGQkODg4CHPmzBEyMjIKuNUsv/LS3zKZTJg+fbpQuXJlwdjYWLCzsxN+/PFH4cWLFwXfcJZnJ06cyPHzWNHH/fv3Fxo3bpztNh4eHoKhoaHg4OAgbNiwIc+PKxEEPi/AGGOMMcZ0Q5HL+WWMMcYYY+xjOPhljDHGGGM6g4NfxhhjjDGmMzj4ZYwxxhhjOoODX8YYY4wxpjM4+GWMMcYYYzqDg1/GGGOMMaYzOPhljDHGGGM6g4NfxhhjjDGmMzj4ZYyxQiwhIQESiQTLli1DzZo1YWxsDFdXV5w5c0bspjHGmFbi4Jcxxgqx8PBwAMD69euxdOlShIeHo0KFCujTpw/kcrm4jWOMMS2kL3YDGGOM5V9ERAQMDAywb98+2NvbAwBmz54NT09PPHz4EHZ2duI2kDHGtAyP/DLGWCEWHh6OLl26KANfADAzMxOvQYwxpuU4+GWMsUIsPDwcHh4eKvtCQ0NhYWEBGxsbcRrFGGNajINfxhgrpN6+fYtbt24hMzNTuU8ul2Pp0qXo378/pFJ+i2eMsQ/xOyNjjBVS165dg0QiwZYtWxAaGoqoqCj4+vri5cuXmDx5stjNY4wxrcTBL2OMFVLh4eFwdnbGzz//jK5du8LT0xOZmZk4efIkSpYsKXbzGGNMK0kEQRDEbgRjjLG8Gzp0KF68eIFt27aJ3RTGGCs0eOSXMcYKqfDwcLi5uYndDMYYK1Q4+GWMsUJIEARcu3aNg1/GGMsjTntgjDHGGGM6g0d+GWOMMcaYzuDglzHGGGOM6QwOfhljjDHGmM7g4JcxxhhjjOkMDn4ZY4wxxpjO4OCXMcYYY4zpDA5+GWOMMcaYzuDglzHGGGOM6QwOfhljjDHGmM7g4JcxxhhjjOkMDn4ZY4wxxpjO+D/wFaf5AobItAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1, axs1 = plt.subplots(1, 1, figsize=(8,3));\n",
    "axs1.plot(np.arange(0, 1.01, 0.01), H, color = 'red');\n",
    "axs1.plot(np.arange(0, 1.01, 0.01), G, color = 'blue');\n",
    "axs1.set_ylabel(\"$function$\");\n",
    "axs1.set_xlabel(\"$p$\");\n",
    "axs1.grid(True)\n",
    "axs1.set_xlim([0,1])\n",
    "axs1.annotate(\"entropy H(p)\",xy=(0.7, 0.85),xytext=(0.35, 0.7),arrowprops={\"width\":1,\"headwidth\":3,'headlength':7});\n",
    "axs1.annotate(\"Gini impurity G(p)\",xy=(0.7, 0.4),xytext=(0.35, 0.2),arrowprops={\"width\":1,\"headwidth\":3,'headlength':7});\n",
    "\n",
    "plt.savefig('fig 54.3.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca93a7",
   "metadata": {},
   "source": [
    "**Figure 54.3** Plot of the entropy function (54.23) for a Boolean random variable as a function of $p\\in[0,1]$, along with a plot of the Gini impurity defined later in (54.43) for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b347a",
   "metadata": {},
   "source": [
    "## Figure 54.6 (decision tree for the FLU example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04dbb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = +1 --> has FLU\n",
    "# label = -1 --> does not have FLU\n",
    "\n",
    "# We will use the mutual information measure to construct the tree\n",
    "\n",
    "import numpy as np\n",
    "features = np.array([[1,0,0,1,0,0],\n",
    "            [1,1,0,0,1,1], [0,1,1,0,1,1],\n",
    "            [0,0,0,1,0,0], [0,1,0,1,1,0],\n",
    "            [1,0,1,0,1,1], [1,0,0,0,0,0],\n",
    "            [0,1,0,1,0,0], [1,1,0,0,0,1], \n",
    "            [1,0,0,0,1,1]])\n",
    "\n",
    "labels = np.array([-1, 1, 1, -1, -1, 1, -1, -1, 1, -1])\n",
    "N = features.shape[0]\n",
    "M = features.shape[1]\n",
    "indexes = np.arange(0,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddd015ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy values for each attribute, H(x) [0.97095059 1.         0.72192809 0.97095059 1.         1.        ]\n",
      "conditional entropy H(x|gamma) for each attribute [0.92451125 0.87548875 0.4        0.5509775  0.87548875 0.39001345]\n",
      "mutual information for each attribute; a column in Table 4 [0.04643934 0.12451125 0.32192809 0.41997309 0.12451125 0.60998655]\n",
      "normalized mutual information for each attribute; a column in Table 4 [0.04782874 0.12451125 0.4459282  0.43253807 0.12451125 0.60998655]\n",
      "Gini measure for each attribute; a column in Table 4 [0.03       0.08333333 0.12       0.21333333 0.08333333 0.33333333]\n",
      "normalized Gini measure for each attribute; a column in Table 4 [0.0625     0.16666667 0.375      0.44444444 0.16666667 0.66666667]\n",
      "if we end at an attribute m, what the label should be when m=1 (first row) and when m=0 (second row) [[ 1.  1.  1. -1.  1.  1.]\n",
      " [-1. -1. -1.  1. -1. -1.]]\n",
      "if we end at an attribute m, how many classification errors occur when m=1 (first row) and when m=0 (second row) [[3. 2. 0. 0. 2. 1.]\n",
      " [1. 1. 2. 2. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# This table starts with the root node in its first row.\n",
    "# Each row contains:\n",
    "# node index, node to its right (if 0, we stop there), label if we stop there, #errors if we stop there, \n",
    "# node to its left (if 0 we stop there), label, #errors\n",
    "\n",
    "counter = 0\n",
    "tree_structure = np.zeros((M, 7))\n",
    "\n",
    "#choosing the top root node\n",
    "H, cond_H, mI, mI_norm, DG, DG_norm, ne, gamma_vec, error_vec = node_tree(features, labels)\n",
    "\n",
    "print('entropy values for each attribute, H(x)', H)\n",
    "print('conditional entropy H(x|gamma) for each attribute', cond_H)\n",
    "print('mutual information for each attribute; a column in Table 4', mI)\n",
    "print('normalized mutual information for each attribute; a column in Table 4', mI_norm)\n",
    "print('Gini measure for each attribute; a column in Table 4', DG)\n",
    "print('normalized Gini measure for each attribute; a column in Table 4', DG_norm)\n",
    "print('if we end at an attribute m, what the label should be when m=1 (first row) and when m=0 (second row)', gamma_vec)\n",
    "print('if we end at an attribute m, how many classification errors occur when m=1 (first row) and when m=0 (second row)', error_vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "134e3747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'root node, labels, and errors'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[ 1. -1.]\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.max(mI) # idx is index of attribute to serve as the root node\n",
    "root = np.argmax(mI)\n",
    "labels_root = gamma_vec[:, root] # a 2x1 vector. Top entry is label to use when root =1; second entry is label to use when root =0\n",
    "errors_root = error_vec[:, root] # a 2x1 vector. Top entry is # errors  when root =1; second entry is# errors when root =0\n",
    "\n",
    "display('root node, labels, and errors')\n",
    "print(root)\n",
    "print(labels_root)\n",
    "print(errors_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc36e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_structure[counter,0] = root;\n",
    "tree_structure[counter,2] = labels_root[0];\n",
    "tree_structure[counter,3] = errors_root[0];\n",
    "tree_structure[counter,5] = labels_root[1];\n",
    "tree_structure[counter,6] = errors_root[1];\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c46a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing the node on the right when root values is 1\n",
      "node index, labels, and errors:\n",
      "1\n",
      "[1. 1.]\n",
      "[0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1888\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1888\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# choosing the node on the right when root assumes value = 1\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "features_1 = np.array([])\n",
    "labels_1 = np.array([])\n",
    "features_0 = np.array([])\n",
    "labels_0 = np.array([])\n",
    "\n",
    "for n in range(N):\n",
    "    if features[n, root] == 1:\n",
    "        if features_1.shape[0] == 0:\n",
    "            features_1 = np.append(features_1, np.concatenate([features[n,0:root], features[n,root+1:M]]))\n",
    "        else:\n",
    "            features_1 = np.vstack((features_1, np.concatenate([features[n,0:root], features[n,root+1:M]])))\n",
    "        \n",
    "        labels_1 = np.append(labels_1, labels[n])\n",
    "        m1 = m1 + 1\n",
    "    else:\n",
    "        if features_0.shape[0] == 0:\n",
    "            features_0 = np.append(features_0 ,np.concatenate([features[n,0:root], features[n,root+1:M]]))\n",
    "        else:\n",
    "            features_0 = np.vstack((features_0, np.concatenate([features[n,0:root], features[n,root+1:M]])))\n",
    "        \n",
    "        labels_0 = np.append(labels_0, labels[n])\n",
    "        m0 = m0 + 1\n",
    "        \n",
    "        \n",
    "indexes_1 = np.concatenate([indexes[0:root], indexes[root+1:M]])\n",
    "M_1 = features_1.shape[1]\n",
    "N_1 = features_1.shape[0]\n",
    "\n",
    "H_1, cond_H_1, mI_1, mI_norm_1, DG_1, DG_norm_1, ne_1, gamma_vec_1, error_vec_1 = node_tree(features_1,labels_1)\n",
    "a_1 = np.max(mI_1)\n",
    "root_1 = np.argmax(mI_1)\n",
    "labels_root_1 = gamma_vec_1[:, root_1] # a 2x1 vector. Top entry is label to use when root =1; second entry is label to use when root =0\n",
    "errors_root_1 = error_vec_1[:, root_1] # a 2x1 vector. Top entry is # errors  when root =1; second entry is# errors when root =0\n",
    "print('choosing the node on the right when root values is 1')\n",
    "print('node index, labels, and errors:')\n",
    "print(root_1)\n",
    "print(labels_root_1)\n",
    "print(errors_root_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f475a9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_structure[counter,1] = indexes_1[root_1];\n",
    "\n",
    "counter = counter+1;\n",
    "tree_structure[counter,0] = indexes_1[root_1];\n",
    "tree_structure[counter,2] = labels_root_1[0];\n",
    "tree_structure[counter,3] = errors_root_1[0];\n",
    "tree_structure[counter,5] = labels_root_1[1];\n",
    "tree_structure[counter,6] = errors_root_1[1];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa8fee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choosing the node on the left when second root value is 0\n",
      "node index, labels, and errors\n",
      "1\n",
      "[ 1. -1.]\n",
      "[0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1888\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1888\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# choosing the node on the left when this second node assumes value 0\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_1b = np.array([])\n",
    "labels_1b = np.array([])\n",
    "features_0b = np.array([])\n",
    "labels_0b = np.array([])\n",
    "\n",
    "for n in range(N_1):\n",
    "    if features_1[n, root_1] == 1:\n",
    "        if features_1b.shape[0] == 0:\n",
    "            features_1b = np.append(features_1b, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M_1]]))\n",
    "        else:\n",
    "            features_1b = np.vstack((features_1b, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]])))\n",
    "        \n",
    "        labels_1b = np.append(labels_1b, labels_1[n])\n",
    "        m1 = m1 + 1\n",
    "    else:\n",
    "        if features_0b.shape[0] == 0:\n",
    "            features_0b = np.append(features_0b ,np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]]))\n",
    "        else:\n",
    "            features_0b = np.vstack((features_0b, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]])))\n",
    "        \n",
    "        labels_0b = np.append(labels_0b, labels_1[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "M_2 = features_0b.shape[1]\n",
    "N_2 = features_0b.shape[0]\n",
    "indexes_0b = np.concatenate([indexes_1[0:root_1], indexes_1[root_1+1:M_1]])\n",
    "\n",
    "H_0b, cond_H_0b, mI_0b, mI_norm_0b, DG_0b, DG_norm_0b, ne_0b, gamma_vec_0b, error_vec_0b = node_tree(features_0b,labels_0b)\n",
    "a_0 = np.max(mI_0b)\n",
    "root_0b = np.argmax(mI_0b)\n",
    "labels_root_0b = gamma_vec_0b[:,root_0b]\n",
    "errors_root_0b = error_vec_0b[:,root_0b]\n",
    "\n",
    "print('choosing the node on the left when second root value is 0')\n",
    "print('node index, labels, and errors')\n",
    "print(root_0b)\n",
    "print(labels_root_0b)\n",
    "print(errors_root_0b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b566ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_structure[counter,4] = indexes_0b[root_0b];\n",
    "\n",
    "counter = counter+1\n",
    "tree_structure[counter,0] = indexes_0b[root_0b]\n",
    "tree_structure[counter,2] = labels_root_0b[0]\n",
    "tree_structure[counter,3] = errors_root_0b[0]\n",
    "tree_structure[counter,5] = labels_root_0b[1]\n",
    "tree_structure[counter,6] = errors_root_0b[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f2c53",
   "metadata": {},
   "source": [
    "## Example 54.3 (Constructing a decision tree for a heart disease dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee759154",
   "metadata": {},
   "source": [
    "We apply the procedure to construct a decision tree for the heart disease dataset. The dataset consists of 297 samples with feature vectors that contain 13 attributes each. These attributes are described in \n",
    "Table 54.7. There are four classes: class 0 (patient has no heart disease) and  classes 1, 2, 3 (patient has heart disease). We group the last three classes into a single class and relabel the feature data into two classes only $\\gamma=+1$ (heart disease is present) and $\\gamma=-1$ (heart disease is absent).\n",
    "\n",
    "**Table 54.7** Original attributes for the heart disease dataset. This dataset is derived from the site https://archive.ics.uci.edu/ml/datasets/heart+Disease. \n",
    "<table style=\"width: 70%;\">\n",
    "    <tr>\n",
    "    <th>Attribute</th>\n",
    "    <th>Explanation</th>\n",
    "    </tr>\n",
    "  <tr>\n",
    "    <th>1</th>\n",
    "    <th> Patient's age measured in year.</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <th>2</th>\n",
    "    <th> Patient's sex (male or female).</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <th>3</th>\n",
    "    <th> Chest pain type: typical angina (value 1), atypical angina (2), non-anginal pain (3), and asymptomatic (4).</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>4</th>\n",
    "    <th> Resting blood pressure measured in mm Hg.</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>5</th>\n",
    "    <th> Serum cholesterol level measured in mg/dl.</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <th>6</th>\n",
    "    <th> Fasting blood sugar level above 120 mg/dl) (1 = true; 0 = false).</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>7</th>\n",
    "    <th> Resting electrocardiographic result: normal (value 0), having ST-T wave abnormality, such as T wave inversions and/or ST elevation or depression larger than 0.05 mV (value 1), or showing probable or definite left ventricular hypertrophy by Estes' criteria (value 2)</th>\n",
    "   </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <th>8</th>\n",
    "    <th> Maximum heart rate measured in beats per minute (bpm).</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>9</th>\n",
    "    <th> Exercise induced angina (1 = yes; 0 = no).</th>\n",
    "   </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <th>10</th>\n",
    "    <th> Size of ST depression induced by exercise relative to rest.</th>\n",
    "   </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <th>11</th>\n",
    "    <th> Slope of the peak exercise ST segment: upsloping (value 1), flat (value 2), or downsloping (value 3).</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>  \n",
    "    <th>12</th>\n",
    "    <th> Number of major vessels colored by fluoroscopy (0, 1, 2, 3).</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "      \n",
    "   <th>13</th>\n",
    "    <th> Thal: 3 = normal; 6 = fixed defect; 7 = reversible defect.</th>\n",
    "   </tr>\n",
    "</table>\n",
    "  \n",
    "\n",
    "The first step in processing the data is to redefine the attributes and replace them by binary-valued variables. Some of the attributes are already binary in nature, such as attribute $6$ (blood sugar level),  and attribute $9$ (exercise induced angina). Other attributes assume real values. There are many ways by which they can be transformed into binary variables. The following procedure is one possibility and is only meant for illustration purposes.\n",
    "\n",
    "Consider, for example, attribute $1$ (patient's age). We compute the average age of all patients in the given dataset. Then, for each patient we set their age variable to $1$ if the patient's age is above the average and to 0 otherwise:\n",
    "\n",
    "$$\n",
    "x =\\begin{cases}\n",
    "1 & \\text{if patient's age is above average}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.54}\n",
    "$$\n",
    "\n",
    "\n",
    "We perform the same transformation for attribute $4$ (resting blood pressure), attribute $5$ (serum cholesterol level), attribute $8$ (heart beat rate), and attribute $10$ (size of ST depression).\n",
    "\n",
    "The remaining attributes are discrete in nature and we can transform them into binary variables as follows. Consider attribute $3$ (chest pain type). There are four types. We therefore introduce four binary variables:\n",
    "\n",
    "$$\n",
    "x_1 = \\begin{cases}\n",
    "1 & \\text{if chest pain is typical angina}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.55a}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "x_2 =\\begin{cases}\n",
    "1 &  \\text{if chest pain is atypical angina}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.55b}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "x_3 = \\begin{cases}\n",
    "1 & \\text{if chest pain is non-anginal pain}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.55c}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "x_4 = \\begin{cases}\n",
    "1 & \\text{if chest pain is asymptomatic}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{55.55d}\n",
    "$$\n",
    "\n",
    "Likewise, for attribute $7$, we have three levels and  introduce three binary variables as follows:\n",
    "\n",
    "$$\n",
    "x_5 = \\begin{cases}\n",
    "1 & \\text{if electrocardiographic result is normal}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.56a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_6 = \\begin{cases}\n",
    "1 & \\text{if electrocardiographic result is abnormal}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.56b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_7 = \\begin{cases}\n",
    "1 &  \\text{if electrocardiographic result shows hypertrophy}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} \\tag{54.56c}\n",
    "$$\n",
    "\n",
    "\n",
    "Similarly, for attributes $11$ (slope of ST segment), $12$ (number of colored vessels), and $13$ (thal condition). In this way, we end up with an expanded feature vector $h'$ with $M'=25$ binary attributes. We will use these expanded features vectors to construct the decision tree. Table 54.8 lists the binary attributes.\n",
    " \n",
    "**Table 54.8** Binary attributes for the heart disease dataset.\n",
    "<table style=\"width: 70%;\">\n",
    "    <tr>\n",
    "    <th>Attribute</th>\n",
    "    <th>Explanation</th>\n",
    "    </tr>\n",
    "  <tr>\n",
    "    <th>1</th>\n",
    "    <th> 1 (patient's age above average), 0 (otherwise).</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <th>2</th>\n",
    "    <th> 1 (male), 0 (female).</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <th>3</th>\n",
    "    <th> 1 (chest pain is typical angina), 0 (otherwise)</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>4</th>\n",
    "    <th> 1 (chest pain is atypical angina), 0 (otherwise)</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>5</th>\n",
    "    <th> 1 (chest pain is non-anginal), 0 (otherwise)</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "    <th>6</th>\n",
    "    <th> 1 (chest pain is non-anginal), 0 (otherwise)</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>7</th>\n",
    "    <th> 1 (blood pressure above average), 0 (otherwise)</th>\n",
    "   </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <th>8</th>\n",
    "    <th> 1 (cholesterol level above average), 0 (otherwise).</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "    <th>9</th>\n",
    "    <th> 1 (blood sugar level above average), 0 (otherwise).</th>\n",
    "   </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <th>10</th>\n",
    "    <th> 1 (electrocardiographic result is normal), 0 (otherwise).</th>\n",
    "   </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <th>11</th>\n",
    "    <th> 1 (electrocardiographic result is abnormal), 0 (otherwise).</th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>  \n",
    "    <th>12</th>\n",
    "    <th> 1 (electrocardiographic result shows hypertrophy), 0 (otherwise).</th>\n",
    "   </tr>\n",
    "  <tr>\n",
    "      \n",
    "   <th>13</th>\n",
    "    <th> 1 (heart rate above average), 0 (otherwise). </th>\n",
    "   </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>14</th>\n",
    "    <th> 1 (if angina is exercise induced), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>15</th>\n",
    "    <th> 1 (if size of ST depression is above average), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>16</th>\n",
    "    <th> 1 (if ST segment is upsloping), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>17</th>\n",
    "    <th> 1 (if ST segment is flat), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>18</th>\n",
    "    <th> 1 (if ST segment is downsloping), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>19</th>\n",
    "    <th> 1 (if no vessels are colored by fluoroscopy), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>20</th>\n",
    "    <th> 1 (if one vessel is colored by fluoroscopy), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>21</th>\n",
    "    <th> 1 (if two vessels are colored by fluoroscopy), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>22</th>\n",
    "    <th> 1 (if three vessels are colored by fluoroscopy), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>23</th>\n",
    "    <th> 1 (if thal condition is normal), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>24</th>\n",
    "    <th> 1 (if thal has fixed defect), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "    \n",
    "  <tr>\n",
    "   <th>25</th>\n",
    "    <th> 1 (if thal has reversible defect), 0 (otherwise).</th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "We select $238$ samples ($80\\%$) for training and use the remaining $59$ samples ($20\\%$) for testing. In the simulation, we employ the mutual information measure to identify the root nodes at the various stages of the tree construction. For example, according to this criterion, the most informative attribute is found to be \n",
    "\n",
    "$$\n",
    "\\text{attribute 6: is the chest pain asymptomatic?} \\tag{54.57}\n",
    "$$\n",
    "\n",
    "If the answer is in the affirmative, and after removing this attribute, the next most informative attribute is found to be \n",
    "\n",
    "$$\n",
    "\\text{attribute 19: are zero vessels colored by fluoroscopy?} \\tag{54.58}\n",
    "$$\n",
    "\n",
    "On the other hand, if the chest pain is not asymptomatic, the next most informative attribute is found to be\n",
    "\n",
    "$$\n",
    "\\text{attribute 23: is the thal condition normal?} \\tag{54.59}\n",
    "$$\n",
    "\n",
    "\n",
    "Figure 54.7 shows several layers of the resulting decision tree, along with the labels at the leaves. The tree is not intended to be a reliable predictor of the presence or absence of heart disease; in this example, the amount of available data is small to enable an accurate classifier. This particular tree results in 16 errors over the $59$ test samples, which corresponds to an empirical error rate of $27.12\\%$ over the test data. It also results in 32 errors over the entire 238 training samples, which corresponds to an empirical error rate of $13.45\\%$ over the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03be014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATING DECISION TREE FOR HEART-DISEASE DATA\n"
     ]
    }
   ],
   "source": [
    "# The heart disease dataset consists of 297 samples with 13 attributes each.\n",
    "# It is derived from the processed cleveland dataset from the site\n",
    "# https://archive.ics.uci.edu/ml/datasets/heart+Disease \n",
    "\n",
    "# The 13 attributes are\n",
    "#\n",
    "# 1. age in years \n",
    "# 2. sex (1:male, 0:female) \n",
    "# 3. chest pain type:  typical angina (value 1), atypical angina (2), \n",
    "#    non-anginal pain (3), asymptomatic (4).\n",
    "# 4. resting blood pressure (in mm Hg on admission to the hospital)  \n",
    "# 5. serum cholesterol in mg/dl  \n",
    "# 6. fasting blood sugar > 120 mg/dl) (1 = true; 0 = false) \n",
    "# 7. resting electrocardiographic results \n",
    "#     a) value 0: normal \n",
    "#     b) value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV) \n",
    "#     c) value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria \n",
    "# 8. maximum heart rate (bpm) achieved \n",
    "# 9. exercise induced angina (1 = yes; 0 = no) \n",
    "# 10. ST depression induced by exercise relative to rest  \n",
    "# 11. Slope of the peak exercise ST segment \n",
    "#     a) value 1: upsloping \n",
    "#     b) value 2: flat \n",
    "#     c) value 3: downsloping  \n",
    "# 12. number of major vessels (0-3) colored by flouroscopy\n",
    "# 13. thal: 3 = normal; 6 = fixed defect; 7 = reversible defect \n",
    "#   \n",
    "#\n",
    "# The class type is\n",
    "#      class 0 (no heart disease): <50% diameter narrowing\n",
    "#      classes 1, 2, 3 (heart disease): >50% diameter narrowing\n",
    "\n",
    "\n",
    "print('GENERATING DECISION TREE FOR HEART-DISEASE DATA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df2d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('./data/heart_disease_data_original.mat') # loaded into variables Ao and labels\n",
    "\n",
    "labels_multi = data['labels']\n",
    "features_org = data['Ao']\n",
    "\n",
    "labels_multi = labels_multi.reshape(-1,) # has five classes 0 (no heart disease) and 1,2,3,4 (heart disease)\n",
    "N = data['Ao'].shape[0]\n",
    "M = data['Ao'].shape[1]-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9dfbccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we transform the labels to +1 (heart disease) and -1 (no heart disease)\n",
    "\n",
    "labels = np.zeros((N,))\n",
    "\n",
    "for n in range(N):\n",
    "    if labels_multi[n] != 0:\n",
    "        labels[n] = 1\n",
    "    else:\n",
    "        labels[n] = -1\n",
    "        \n",
    "# We transform the features into binary values\n",
    " \n",
    "# Age is in years. we compute the average age and replace by 1 if age\n",
    "# larger than average, and 0 otherwise\n",
    "         \n",
    "features = np.zeros((N, M+3+2+2+3+2+1))\n",
    "\n",
    "mean_age = np.mean(features_org[:,0])\n",
    "for n in range(N):\n",
    "    if features_org[n, 0] >= mean_age:\n",
    "        features[n, 0] = 1\n",
    "    else:\n",
    "        features[n, 0] = 0\n",
    "\n",
    "# sex (male=1,female=0) is already binary        \n",
    "features[:, 1] = features_org[:, 1]\n",
    "\n",
    "# chest pain type:  typical angina (value 1), atypical angina (2), \n",
    "# non-anginal pain (3), asymptomatic (4).\n",
    "# we make each a binary value and therefore replace this column by four columns \n",
    "\n",
    "for n in range(N):\n",
    "    if features_org[n, 2] == 1:\n",
    "        features[n, 2] = 1\n",
    "        \n",
    "    if features_org[n, 2] == 2:\n",
    "        features[n, 3] = 1\n",
    "        \n",
    "    if features_org[n, 2] == 3:\n",
    "        features[n, 4] = 1\n",
    "    \n",
    "    if features_org[n, 2] == 4:\n",
    "        features[n, 5] = 1\n",
    "\n",
    "        \n",
    "# Resting blood pressure measured in mm Hg\n",
    "# We compute its average and replace by a binary variable (larger or smaller than average)\n",
    " \n",
    "mean_pressure = np.mean(features_org[:,3])\n",
    "for n in range(N):\n",
    "    if features_org[n, 3] >= mean_pressure:\n",
    "        features[n, 6] = 1\n",
    "    else:\n",
    "        features[n, 6] = 0\n",
    "\n",
    "\n",
    "# Serum cholesteral measured in mg/dl  \n",
    "# We compute its average and replace by a binary variable (larger or\n",
    "# smaller than average)\n",
    " \n",
    "mean_serum = np.mean(features_org[:,4])\n",
    "for n in range(N):\n",
    "    if features_org[n, 4] >= mean_serum:\n",
    "        features[n, 7] = 1\n",
    "    else:\n",
    "        features[n, 7] = 0\n",
    "\n",
    "# fasting blood sugar > 120 mg/dl is binary already     \n",
    "features[:, 8] = features_org[:, 5]\n",
    "\n",
    "# resting electrocardiographic results has 3 values; we add 3 binary\n",
    "# columns\n",
    "\n",
    "for n in range(N):\n",
    "    if features_org[n, 6] == 0:\n",
    "        features[n, 9] = 1\n",
    "        \n",
    "    if features_org[n, 6] == 1:\n",
    "        features[n, 10] = 1\n",
    "        \n",
    "    if features_org[n, 6] == 2:\n",
    "        features[n, 11] = 1\n",
    "        \n",
    "# maximum heart rate in bpm\n",
    "# we compute the average and replace by a binary column (larger or smaller\n",
    "# than average)\n",
    "\n",
    "mean_rate = np.mean(features_org[:,7]);\n",
    "for n in range(N):\n",
    "    if features_org[n,7] >= mean_rate:\n",
    "        features[n,12] = 1;\n",
    "    else:\n",
    "        features[n,12] = 0;\n",
    "        \n",
    "# exercise induced angina is binary already\n",
    "\n",
    "features[:, 13] = features_org[:, 8]\n",
    "\n",
    "# ST depression induced by exercise relative to rest.\n",
    "# We compute average and transform into binary column (larger or smaller\n",
    "# than average)\n",
    "\n",
    "mean_ST = np.mean(features_org[:,9])\n",
    "for n in range(N):\n",
    "    if features_org[n, 9] >= mean_ST:\n",
    "        features[n, 14] = 1\n",
    "\n",
    "# Slope of the peak exercise ST segment has 3 values. We replace by three\n",
    "# binary columns\n",
    "\n",
    "for n in range(N):\n",
    "    if features_org[n, 10] == 1:\n",
    "        features[n, 15] = 1\n",
    "        \n",
    "    if features_org[n, 10] == 2:\n",
    "        features[n, 16] = 1\n",
    "        \n",
    "    if features_org[n, 10] == 3:\n",
    "        features[n, 17] = 1\n",
    "        \n",
    "# number of major vessels (0-3) colored by flourosopy\n",
    "# We replace by four binary columns \n",
    "\n",
    "for n in range(N):\n",
    "    if features_org[n, 11] == 0:\n",
    "        features[n, 18] = 1\n",
    "        \n",
    "    if features_org[n, 11] == 1:\n",
    "        features[n, 19] = 1\n",
    "        \n",
    "    if features_org[n, 11] == 2:\n",
    "        features[n, 20] = 1\n",
    "        \n",
    "    if features_org[n, 11] == 3:\n",
    "        features[n, 21] = 1\n",
    "\n",
    "# thal has 3 values. We replace by three binary columns\n",
    "\n",
    "for n in range(N):\n",
    "    if features_org[n, 12] == 3:\n",
    "        features[n, 22] = 1\n",
    "    \n",
    "    if features_org[n, 12] == 6:\n",
    "        features[n, 23] = 1\n",
    "    \n",
    "    if features_org[n, 12] == 7:\n",
    "        features[n, 24] = 1\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a1c71cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: root node, labels, and errors; press ENTER\n",
      "5\n",
      "[ 1. -1.]\n",
      "[31. 25.]\n"
     ]
    }
   ],
   "source": [
    "# training and test data\n",
    "\n",
    "N = features.shape[0] # total number of data points\n",
    "M = features.shape[1]\n",
    "N_test = np.fix(0.2*N) # number of test data separated for testing (20%)\n",
    "\n",
    "features_train = features[0:int(N-N_test), :]\n",
    "labels_train = labels[0:int(N-N_test)]\n",
    "\n",
    "features_test = features[int(N-N_test):, :]\n",
    "labels_test = labels[int(N-N_test):]\n",
    "\n",
    "indexes = np.arange(0, M)\n",
    "\n",
    "# choosing the ROOT node\n",
    "H, cond_H, mI, mI_norm, DG, DG_norm, ne, gamma_vec, error_vec = node_tree(features_train, labels_train);\n",
    "\n",
    "a = np.max(mI)\n",
    "root = np.argmax(mI)\n",
    "labels_root = gamma_vec[:, root] # a 2x1 vector. Top entry is label to use when root =1; second entry is label to use when root =0\n",
    "errors_root = error_vec[:, root] # a 2x1 vector. Top entry is # errors  when root =1; second entry is# errors when root =0\n",
    "\n",
    "print('ROOT: root node, labels, and errors; press ENTER')\n",
    "print(root)\n",
    "print(labels_root)\n",
    "print(errors_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "950c6697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_1: choosing the node on the right of ROOT when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "18\n",
      "[-1.  1.]\n",
      "[25.  3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# let us now choose the nodes to its left and right.\n",
    "# choosing the node to the right of ROOT (i.e., when ROOT assumes value = 1)\n",
    "\n",
    "\n",
    "features_0 = np.array([])\n",
    "features_1 = np.array([])\n",
    "labels_0 = np.array([])\n",
    "labels_1 = np.array([])\n",
    "N_train = features_train.shape[0]\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "# we remove the root attribute and split the features into two sets: those with root=1 and those with root=0\n",
    "\n",
    "for n in range(N_train):\n",
    "    if features_train[n, root] == 1:\n",
    "        if features_1.shape[0] == 0:\n",
    "            features_1 = np.append(features_1, np.concatenate([features_train[n,0:root], features_train[n,root+1:M]]))  \n",
    "        else:    \n",
    "            features_1 = np.vstack((features_1, np.concatenate([features_train[n,0:root], features_train[n,root+1:M]])))   \n",
    "        \n",
    "        labels_1 = np.append(labels_1, labels_train[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_0.shape[0] == 0:\n",
    "            features_0 = np.append(features_0, np.concatenate([features_train[n,0:root], features_train[n,root+1:M]]))    \n",
    "        else:\n",
    "            features_0 = np.vstack((features_0, np.concatenate([features_train[n,0:root], features_train[n,root+1:M]])))    \n",
    "        \n",
    "        labels_0 = np.append(labels_0, labels_train[n])\n",
    "        m0 = m0 + 1\n",
    "        \n",
    "\n",
    "indexes_1 = np.concatenate([indexes[0:root], indexes[root+1:M]])\n",
    "M_1 = features_1.shape[1]\n",
    "M_0 = features_0.shape[1]\n",
    "N_1 = features_1.shape[0]\n",
    "N_0 = features_0.shape[0]\n",
    "\n",
    "H_1, cond_H_1, mI_1, mI_norm_1, DG_1, DG_norm_1, ne_1, gamma_vec_1, error_vec_1 = node_tree(features_1, labels_1);\n",
    "\n",
    "a_1 = np.max(mI_1)\n",
    "root_1 = np.argmax(mI_1)\n",
    "labels_root_1 = gamma_vec_1[:, root_1]\n",
    "errors_root_1 = error_vec_1[:, root_1]\n",
    "\n",
    "print('ROOT_1: choosing the node on the right of ROOT when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_1[root_1])\n",
    "print(labels_root_1)\n",
    "print(errors_root_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b7c7cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_0: choosing the node on the left of ROOT when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "22\n",
      "[-1. -1.]\n",
      "[ 8. 17.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# choosing the node on the left when ROOT assumes value = 0\n",
    "\n",
    "H_0, cond_H_0, mI_0, mI_norm_0, DG_0, DG_norm_0, ne_0, gamma_vec_0, error_vec_0 = node_tree(features_0, labels_0)\n",
    "a_0 = np.max(mI_0)\n",
    "root_0 = np.argmax(mI_0)\n",
    "labels_root_0 = gamma_vec_0[:,root_0]  \n",
    "errors_root_0 = error_vec_0[:,root_0] \n",
    "\n",
    "print('ROOT_0: choosing the node on the left of ROOT when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_1[root_0])\n",
    "print(labels_root_0)\n",
    "print(errors_root_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efc0224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_11: choosing the node on the right of ROOT_1 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "24\n",
      "[ 1. -1.]\n",
      "[5. 5.]\n",
      "ROOT_10: choosing the node on the left of ROOT_1 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "13\n",
      "[1. 1.]\n",
      "[0. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# let us now choose the nodes to the left and right of ROOT_1\n",
    "# choosing the node to the right of ROOT_1 (i.e., when ROOT assumes value = 1)\n",
    "\n",
    "\n",
    "indexes_21 = np.concatenate([indexes_1[0:root_1], indexes_1[root_1+1:M_1]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_11 = np.array([])\n",
    "features_10 = np.array([])\n",
    "labels_11 = np.array([])\n",
    "labels_10 = np.array([])\n",
    "\n",
    "for n in range(N_1):\n",
    "    if features_1[n, root_1] == 1:\n",
    "        if features_11.shape[0] == 0:\n",
    "            features_11 = np.append(features_11, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]]))  \n",
    "        else:    \n",
    "            features_11 = np.vstack((features_11, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]])))   \n",
    "        \n",
    "        labels_11 = np.append(labels_11, labels_1[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_10.shape[0] == 0:\n",
    "            features_10 = np.append(features_10, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]]))    \n",
    "        else:\n",
    "            features_10 = np.vstack((features_10, np.concatenate([features_1[n,0:root_1], features_1[n,root_1+1:M]])))    \n",
    "        \n",
    "        labels_10 = np.append(labels_10, labels_1[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "M_11 = features_11.shape[1]\n",
    "M_10 = features_10.shape[1]\n",
    "N_11 = features_11.shape[0]\n",
    "N_10 = features_10.shape[0]\n",
    "\n",
    "H_11, cond_H_11, mI_11, mI_norm_11, DG_11, DG_norm_11, ne_11, gamma_vec_11, error_vec_11 = node_tree(features_11,labels_11)\n",
    "a_11 = np.max(mI_11)\n",
    "root_11 = np.argmax(mI_11)\n",
    "labels_root_11 = gamma_vec_11[:,root_11]  \n",
    "errors_root_11 = error_vec_11[:,root_11] \n",
    "\n",
    "print('ROOT_11: choosing the node on the right of ROOT_1 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_21[root_11])\n",
    "print(labels_root_11)\n",
    "print(errors_root_11)\n",
    "\n",
    "# choosing the node on the left when ROOT_1 assumes value = 0\n",
    "\n",
    "H_10, cond_H_10, mI_10, mI_norm_10, DG_10, DG_norm_10, ne_10, gamma_vec_10, error_vec_10 = node_tree(features_10,labels_10);\n",
    "a_10 = np.max(mI_10)\n",
    "root_10 = np.argmax(mI_10)\n",
    "labels_root_10 = gamma_vec_10[:,root_10]  \n",
    "errors_root_10 = error_vec_10[:,root_10] \n",
    "\n",
    "print('ROOT_10: choosing the node on the left of ROOT_1 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_21[root_10])\n",
    "print(labels_root_10)\n",
    "print(errors_root_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb6b0cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_01: choosing the node on the right of ROOT_0 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "1\n",
      "[-1. -1.]\n",
      "[8. 0.]\n",
      "ROOT_00: choosing the node on the left of ROOT_0 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "18\n",
      "[-1.  1.]\n",
      "[5. 4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "#% let us now choose the nodes to the left and right of ROOT_0\n",
    "# choosing the node to the right of ROOT_0 (i.e., when ROOT_0 assumes value = 1)\n",
    "\n",
    "indexes_20 = np.concatenate([indexes_1[0:root_0], indexes_1[root_0+1:M_0]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_01 = np.array([])\n",
    "features_00 = np.array([])\n",
    "labels_01 = np.array([])\n",
    "labels_00 = np.array([])\n",
    "\n",
    "for n in range(N_0):\n",
    "    if features_0[n, root_0] == 1:\n",
    "        if features_01.shape[0] == 0:\n",
    "            features_01 = np.append(features_01, np.concatenate([features_0[n,0:root_0], features_0[n,root_0+1:M_0]]))  \n",
    "        else:    \n",
    "            features_01 = np.vstack((features_01, np.concatenate([features_0[n,0:root_0], features_0[n,root_0+1:M_0]])))   \n",
    "        \n",
    "        labels_01 = np.append(labels_01, labels_0[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_00.shape[0] == 0:\n",
    "            features_00 = np.append(features_00, np.concatenate([features_0[n,0:root_0], features_0[n,root_0+1:M_0]]))    \n",
    "        else:\n",
    "            features_00 = np.vstack((features_00, np.concatenate([features_0[n,0:root_0], features_0[n,root_0+1:M_0]])))    \n",
    "        \n",
    "        labels_00 = np.append(labels_00, labels_0[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "M_01 = features_01.shape[1]\n",
    "M_00 = features_00.shape[1]\n",
    "N_01 = features_01.shape[0]\n",
    "N_00 = features_00.shape[0]\n",
    "\n",
    "H_01, cond_H_01, mI_01, mI_norm_01, DG_01, DG_norm_01, ne_01, gamma_vec_01, error_vec_01 = node_tree(features_01,labels_01);\n",
    "a_01 = np.max(mI_01)\n",
    "root_01 = np.argmax(mI_01)\n",
    "labels_root_01 = gamma_vec_01[:,root_01] \n",
    "errors_root_01 = error_vec_01[:,root_01] \n",
    "\n",
    "print('ROOT_01: choosing the node on the right of ROOT_0 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_20[root_01])\n",
    "print(labels_root_01)\n",
    "print(errors_root_01)\n",
    "\n",
    "# choosing the node on the left when ROOT_0 assumes value = 0\n",
    "\n",
    "H_00, cond_H_00, mI_00, mI_norm_00, DG_00, DG_norm_00, ne_00, gamma_vec_00, error_vec_00 = node_tree(features_00,labels_00);\n",
    "a_00 = np.max(mI_00)\n",
    "root_00 = np.argmax(mI_00)\n",
    "labels_root_00 = gamma_vec_00[:,root_00]  \n",
    "errors_root_00 = error_vec_00[:,root_00]\n",
    "\n",
    "print('ROOT_00: choosing the node on the left of ROOT_0 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_20[root_00])\n",
    "print(labels_root_00)\n",
    "print(errors_root_00)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd0cf20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_111: choosing the node on the right of ROOT_11 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "14\n",
      "[1. 1.]\n",
      "[0. 5.]\n",
      "ROOT_110: choosing the node on the left of ROOT_11 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "0\n",
      "[-1. -1.]\n",
      "[5. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# % let us now choose the nodes to the left and right of ROOT_11\n",
    "# choosing the node to the right of ROOT_11 (i.e., when ROOT_11 assumes value = 1)\n",
    "\n",
    "\n",
    "indexes_31 = np.concatenate([indexes_21[0:root_11], indexes_21[root_11+1:M_11]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_111 = np.array([])\n",
    "features_110 = np.array([])\n",
    "labels_111 = np.array([])\n",
    "labels_110 = np.array([])\n",
    "\n",
    "for n in range(N_11):\n",
    "    if features_11[n, root_11] == 1:\n",
    "        if features_111.shape[0] == 0:\n",
    "            features_111 = np.append(features_111, np.concatenate([features_11[n,0:root_11], features_11[n,root_11+1:M_11]]))  \n",
    "        else:    \n",
    "            features_111 = np.vstack((features_111, np.concatenate([features_11[n,0:root_11], features_11[n,root_11+1:M_11]])))   \n",
    "        \n",
    "        labels_111 = np.append(labels_111, labels_11[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_110.shape[0] == 0:\n",
    "            features_110 = np.append(features_110, np.concatenate([features_11[n,0:root_11], features_11[n,root_11+1:M_11]]))    \n",
    "        else:\n",
    "            features_110 = np.vstack((features_110, np.concatenate([features_11[n,0:root_11], features_11[n,root_11+1:M_11]])))    \n",
    "        \n",
    "        labels_110 = np.append(labels_110, labels_11[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "M_111 = features_111.shape[1]\n",
    "M_110 = features_110.shape[1]\n",
    "N_111 = features_111.shape[0]\n",
    "N_110 = features_110.shape[0]\n",
    "\n",
    "H_111, cond_H_111, mI_111, mI_norm_111, DG_111, DG_norm_111, ne_111, gamma_vec_111, error_vec_111 = node_tree(features_111,labels_111)\n",
    "a_111 = np.max(mI_111)\n",
    "root_111 = np.argmax(mI_111)\n",
    "labels_root_111 = gamma_vec_111[:,root_111]  \n",
    "errors_root_111 = error_vec_111[:,root_111]  \n",
    "\n",
    "print('ROOT_111: choosing the node on the right of ROOT_11 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_31[root_111])\n",
    "print(labels_root_111)\n",
    "print(errors_root_111)\n",
    "\n",
    "# choosing the node on the left when ROOT_11 assumes value = 0\n",
    "\n",
    "H_110, cond_H_110, mI_110, mI_norm_110, DG_110, DG_norm_110, ne_110, gamma_vec_110, error_vec_110 = node_tree(features_110,labels_110)\n",
    "a_110 = np.max(mI_110)\n",
    "root_110 = np.argmax(mI_110)\n",
    "labels_root_110 = gamma_vec_110[:,root_110]\n",
    "errors_root_110 = error_vec_110[:,root_110] \n",
    "\n",
    "print('ROOT_110: choosing the node on the left of ROOT_11 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_31[root_110])\n",
    "print(labels_root_110)\n",
    "print(errors_root_110)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39e3f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_101: choosing the node on the right of ROOT_10 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "0\n",
      "[1. 1.]\n",
      "[0. 0.]\n",
      "ROOT_100: choosing the node on the left of ROOT_10 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "6\n",
      "[1. 1.]\n",
      "[0. 3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "#  let us now choose the nodes to the left and right of ROOT_10\n",
    "# choosing the node to the right of ROOT_10 (i.e., when ROOT_10 assumes value = 1)\n",
    "\n",
    "\n",
    "indexes_30 = np.concatenate([indexes_21[0:root_10], indexes_21[root_10+1:M_10]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_101 = np.array([])\n",
    "features_100 = np.array([])\n",
    "labels_101 = np.array([])\n",
    "labels_100 = np.array([])\n",
    "\n",
    "for n in range(N_10):\n",
    "    if features_10[n, root_10] == 1 :\n",
    "        if features_101.shape[0] == 0:\n",
    "            features_101 = np.append(features_101, np.concatenate([features_10[n,0:root_10], features_10[n,root_10+1:M_10]]))  \n",
    "        else:    \n",
    "            features_101 = np.vstack((features_101, np.concatenate([features_10[n,0:root_10], features_10[n,root_10+1:M_10]])))   \n",
    "        \n",
    "        labels_101 = np.append(labels_101, labels_10[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_100.shape[0] == 0:\n",
    "            features_100 = np.append(features_100, np.concatenate([features_10[n,0:root_10], features_10[n,root_10+1:M_10]]))    \n",
    "        else:\n",
    "            features_100 = np.vstack((features_100, np.concatenate([features_10[n,0:root_10], features_10[n,root_10+1:M_10]])))    \n",
    "        \n",
    "        labels_100 = np.append(labels_100, labels_10[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "M_101 = features_101.shape[1]\n",
    "M_100 = features_100.shape[1]\n",
    "N_101 = features_101.shape[0]\n",
    "N_100 = features_100.shape[0]\n",
    "\n",
    "H_101, cond_H_101, mI_101, mI_norm_101, DG_101, DG_norm_101, ne_101, gamma_vec_101, error_vec_101 = node_tree(features_101,labels_101);\n",
    "a_101 = np.max(mI_101)\n",
    "root_101 = np.argmax(mI_101)\n",
    "labels_root_101 = gamma_vec_101[:,root_101] \n",
    "errors_root_101 = error_vec_101[:,root_101] \n",
    "\n",
    "print('ROOT_101: choosing the node on the right of ROOT_10 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_101[:,root_101][0] == 0 and error_vec_101[:,root_101][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_30[root_101])\n",
    "print(labels_root_101)\n",
    "print(errors_root_101)\n",
    "\n",
    "# choosing the node on the left when ROOT_10 assumes value = 0\n",
    "\n",
    "H_100, cond_H_100, mI_100, mI_norm_100, DG_100, DG_norm_100, ne_100, gamma_vec_100, error_vec_100 = node_tree(features_100,labels_100)\n",
    "a_100 = np.max(mI_100)\n",
    "root_100 = np.argmax(mI_100)\n",
    "labels_root_100 = gamma_vec_100[:,root_100] \n",
    "errors_root_100 = error_vec_100[:,root_100]\n",
    "\n",
    "if error_vec_100[:,root_100][0] == 0 and error_vec_100[:,root_100][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print('ROOT_100: choosing the node on the left of ROOT_10 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "print(indexes_30[root_100])\n",
    "print(labels_root_100)\n",
    "print(errors_root_100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81c297e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_011: choosing the node on the right of ROOT_01 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "0\n",
      "[-1. -1.]\n",
      "[5. 3.]\n",
      "ROOT_010: choosing the node on the left of ROOT_01 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "0\n",
      "[-1. -1.]\n",
      "[0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# let us now choose the nodes to the left and right of ROOT_01\n",
    "# choosing the node to the right of ROOT_01 (i.e., when ROOT_01 assumes value = 1)\n",
    "\n",
    "\n",
    "indexes_31 = np.concatenate([indexes_20[0:root_01], indexes_20[root_01+1:M_01]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_011 = np.array([])\n",
    "features_010 = np.array([])\n",
    "labels_011 = np.array([])\n",
    "labels_010 = np.array([])\n",
    "\n",
    "for n in range(N_01):\n",
    "    if features_01[n, root_01] == 1 :\n",
    "        if features_011.shape[0] == 0:\n",
    "            features_011 = np.append(features_011, np.concatenate([features_01[n,0:root_01], features_01[n,root_01+1:M_01]]))  \n",
    "        else:    \n",
    "            features_011 = np.vstack((features_011, np.concatenate([features_01[n,0:root_01], features_01[n,root_01+1:M_01]])))   \n",
    "        \n",
    "        labels_011 = np.append(labels_011, labels_01[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_010.shape[0] == 0:\n",
    "            features_010 = np.append(features_010, np.concatenate([features_01[n,0:root_01], features_01[n,root_01+1:M_01]]))    \n",
    "        else:\n",
    "            features_010 = np.vstack((features_010, np.concatenate([features_01[n,0:root_01], features_01[n,root_01+1:M_01]])))    \n",
    "        \n",
    "        labels_010 = np.append(labels_010, labels_01[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "H_011, cond_H_011, mI_011, mI_norm_011, DG_011, DG_norm_011, ne_011, gamma_vec_011, error_vec_011 = node_tree(features_011,labels_011)\n",
    "a_011 = np.max(mI_011)\n",
    "root_011 = np.argmax(mI_011)\n",
    "labels_root_011 = gamma_vec_011[:,root_011]  \n",
    "errors_root_011 = error_vec_011[:,root_011]\n",
    "\n",
    "print('ROOT_011: choosing the node on the right of ROOT_01 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_011[:,root_011][0] == 0 and error_vec_011[:,root_011][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_31[root_011])\n",
    "print(labels_root_011)\n",
    "print(errors_root_011)\n",
    "\n",
    "# % choosing the node on the left when ROOT_01 assumes value = 0\n",
    "\n",
    "H_010, cond_H_010, mI_010, mI_norm_010, DG_010, DG_norm_010, ne_010, gamma_vec_010, error_vec_010 = node_tree(features_010,labels_010)\n",
    "a_010 = np.max(mI_010)\n",
    "root_010 = np.argmax(mI_010)\n",
    "labels_root_010 = gamma_vec_010[:,root_010] \n",
    "errors_root_010 = error_vec_010[:,root_010]\n",
    "\n",
    "print('ROOT_010: choosing the node on the left of ROOT_01 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_010[:,root_010][0] == 0 and error_vec_010[:,root_010][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_31[root_010])\n",
    "print(labels_root_010)\n",
    "print(errors_root_010)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "360fe161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_001: choosing the node on the right of ROOT_00 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "13\n",
      "[ 1. -1.]\n",
      "[2. 2.]\n",
      "ROOT_000: choosing the node on the left of ROOT_00 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "9\n",
      "[1. 1.]\n",
      "[4. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "#  let us now choose the nodes to the left and right of ROOT_00\n",
    "# choosing the node to the right of ROOT_00 (i.e., when ROOT_00 assumes value = 1)\n",
    "\n",
    "\n",
    "indexes_30 = np.concatenate([indexes_20[0:root_00], indexes_20[root_00+1:M_00]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_001 = np.array([])\n",
    "features_000 = np.array([])\n",
    "labels_001 = np.array([])\n",
    "labels_000 = np.array([])\n",
    "\n",
    "for n in range(N_00):\n",
    "    if features_00[n, root_00] == 1 :\n",
    "        if features_001.shape[0] == 0:\n",
    "            features_001 = np.append(features_001, np.concatenate([features_00[n,0:root_00], features_00[n,root_00+1:M_00]]))  \n",
    "        else:    \n",
    "            features_001 = np.vstack((features_001, np.concatenate([features_00[n,0:root_00], features_00[n,root_00+1:M_00]])))   \n",
    "        \n",
    "        labels_001 = np.append(labels_001, labels_00[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_000.shape[0] == 0:\n",
    "            features_000 = np.append(features_000, np.concatenate([features_00[n,0:root_00], features_00[n,root_00+1:M_00]]))    \n",
    "        else:\n",
    "            features_000 = np.vstack((features_000, np.concatenate([features_00[n,0:root_00], features_00[n,root_00+1:M_00]])))    \n",
    "        \n",
    "        labels_000 = np.append(labels_000, labels_00[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "H_001, cond_H_001, mI_001, mI_norm_001, DG_001, DG_norm_001, ne_001, gamma_vec_001, error_vec_001 = node_tree(features_001,labels_001);\n",
    "a_001 = np.max(mI_001)\n",
    "root_001 = np.argmax(mI_001)\n",
    "labels_root_001 = gamma_vec_001[:,root_001] \n",
    "errors_root_001 = error_vec_001[:,root_001] \n",
    "\n",
    "print('ROOT_001: choosing the node on the right of ROOT_00 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_001[:,root_001][0] == 0 and error_vec_001[:,root_001][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_30[root_001])\n",
    "print(labels_root_001)\n",
    "print(errors_root_001)\n",
    "\n",
    "# choosing the node on the left when ROOT_01 assumes value = 0\n",
    "\n",
    "H_000, cond_H_000, mI_000, mI_norm_000, DG_000, DG_norm_000, ne_000, gamma_vec_000, error_vec_000 = node_tree(features_000,labels_000)\n",
    "a_000 = np.max(mI_000)\n",
    "root_000 = np.argmax(mI_000)\n",
    "labels_root_000 = gamma_vec_000[:,root_000] \n",
    "errors_root_000 = error_vec_000[:,root_000]\n",
    "\n",
    "print('ROOT_000: choosing the node on the left of ROOT_00 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_000[:,root_000][0] == 0 and error_vec_000[:,root_000][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_30[root_000])\n",
    "print(labels_root_000)\n",
    "print(errors_root_000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2da8c499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_1110: choosing the node on the left of ROOT_111 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "10\n",
      "[-1.  1.]\n",
      "[0. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# let us now choose the node to the left of ROOT_111\n",
    "\n",
    "M_111 = features_111.shape[1]\n",
    "M_110 = features_110.shape[1]\n",
    "N_111 = features_111.shape[0]\n",
    "N_110 = features_110.shape[0]\n",
    "\n",
    "indexes_311 = np.concatenate([indexes_31[0:root_111], indexes_31[root_111+1:M_111]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_1111 = np.array([])\n",
    "features_1110 = np.array([])\n",
    "labels_1111 = np.array([])\n",
    "labels_1110 = np.array([])\n",
    "\n",
    "for n in range(N_111):\n",
    "    if features_111[n, root_111] == 1 :\n",
    "        if features_1111.shape[0] == 0:\n",
    "            features_1111 = np.append(features_1111, np.concatenate([features_111[n,0:root_111], features_111[n,root_111+1:M_111]]))  \n",
    "        else:    \n",
    "            features_1111 = np.vstack((features_1111, np.concatenate([features_111[n,0:root_111], features_111[n,root_111+1:M_111]])))   \n",
    "        \n",
    "        labels_1111 = np.append(labels_1111, labels_111[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_1110.shape[0] == 0:\n",
    "            features_1110 = np.append(features_1110, np.concatenate([features_111[n,0:root_111], features_111[n,root_111+1:M_111]]))    \n",
    "        else:\n",
    "            features_1110 = np.vstack((features_1110, np.concatenate([features_111[n,0:root_111], features_111[n,root_111+1:M_111]])))    \n",
    "        \n",
    "        labels_1110 = np.append(labels_1110, labels_111[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "H_1110, cond_H_1110, mI_1110, mI_norm_1110, DG_1110, DG_norm_1110, ne_1110, gamma_vec_1110, error_vec_1110 = node_tree(features_1110,labels_1110)\n",
    "a_1110 = np.max(mI_1110)\n",
    "root_1110 = np.argmax(mI_1110)\n",
    "labels_root_1110 = gamma_vec_1110[:,root_1110] \n",
    "errors_root_1110 = error_vec_1110[:,root_1110] \n",
    "\n",
    "print('ROOT_1110: choosing the node on the left of ROOT_111 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_1110[:,root_1110][0] == 0 and error_vec_1110[:,root_1110][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_311[root_1110])\n",
    "print(labels_root_1110)\n",
    "print(errors_root_1110)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66d3fe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_1101: choosing the node on the right of ROOT_110 when its value is 1\n",
      "node index, labels, and errors: press ENTER\n",
      "2\n",
      "[-1.  1.]\n",
      "[0. 5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# let us now choose the node to the right of ROOT_110\n",
    "\n",
    "indexes_310 = np.concatenate([indexes_31[0:root_110], indexes_31[root_110+1:M_110]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_1101 = np.array([])\n",
    "features_1100 = np.array([])\n",
    "labels_1101 = np.array([])\n",
    "labels_1100 = np.array([])\n",
    "\n",
    "for n in range(N_110):\n",
    "    if features_110[n, root_110] == 1 :\n",
    "        if features_1101.shape[0] == 0:\n",
    "            features_1101 = np.append(features_1101, np.concatenate([features_110[n,0:root_110], features_110[n,root_110+1:M_110]]))  \n",
    "        else:    \n",
    "            features_1101 = np.vstack((features_1101, np.concatenate([features_110[n,0:root_110], features_110[n,root_110+1:M_110]])))   \n",
    "        \n",
    "        labels_1101 = np.append(labels_1101, labels_110[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_1100.shape[0] == 0:\n",
    "            features_1100 = np.append(features_1100, np.concatenate([features_110[n,0:root_110], features_110[n,root_110+1:M_110]]))    \n",
    "        else:\n",
    "            features_1100 = np.vstack((features_1100, np.concatenate([features_110[n,0:root_110], features_110[n,root_110+1:M_110]])))    \n",
    "        \n",
    "        labels_1100 = np.append(labels_1100, labels_110[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "H_1101, cond_H_1101, mI_1101, mI_norm_1101, DG_1101, DG_norm_1101, ne_1101, gamma_vec_1101, error_vec_1101 = node_tree(features_1101,labels_1101)\n",
    "a_1101 = np.max(mI_1101)\n",
    "root_1101 = np.argmax(mI_1101)\n",
    "labels_root_1101 = gamma_vec_1101[:,root_1101] \n",
    "errors_root_1101 = error_vec_1101[:,root_1101] \n",
    "\n",
    "print('ROOT_1101: choosing the node on the right of ROOT_110 when its value is 1')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_1101[:,root_1101][0] == 0 and error_vec_1101[:,root_1101][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_310[root_1101])\n",
    "print(labels_root_1101)\n",
    "print(errors_root_1101)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d133305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_11010: choosing the node on the left of ROOT_1101 when its value is 0\n",
      "node index, labels, and errors: press ENTER\n",
      "3\n",
      "[1. 1.]\n",
      "[0. 5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:142: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mI_norm[m] = mI[m]/H[m] # normalized mutual information\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_21592\\4069945845.py:145: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  DG_norm[m] = DG[m]/G[m] # normalized Gini gain ratio\n"
     ]
    }
   ],
   "source": [
    "# % let us now choose the node to the left of ROOT_1101\n",
    "\n",
    "M_1101 = features_1101.shape[1]\n",
    "N_1101 = features_1101.shape[0]\n",
    "\n",
    "indexes_410 = np.concatenate([indexes_310[0:root_1101], indexes_310[root_1101+1:M_1101]])\n",
    "\n",
    "m1 = 0\n",
    "m0 = 0\n",
    "\n",
    "features_11011 = np.array([])\n",
    "features_11010 = np.array([])\n",
    "labels_11011 = np.array([])\n",
    "labels_11010 = np.array([])\n",
    "\n",
    "for n in range(N_1101):\n",
    "    if features_1101[n, root_1101] == 1 :\n",
    "        if features_11011.shape[0] == 0:\n",
    "            features_11011 = np.append(features_11011, np.concatenate([features_1101[n,0:root_1101], features_1101[n,root_1101+1:M_1101]]))  \n",
    "        else:    \n",
    "            features_11011 = np.vstack((features_11011, np.concatenate([features_1101[n,0:root_1101], features_1101[n,root_1101+1:M_1101]])))   \n",
    "        \n",
    "        labels_11011 = np.append(labels_11011, labels_1101[n])\n",
    "        m1 = m1 + 1\n",
    "        \n",
    "    else:\n",
    "        if features_11010.shape[0] == 0:\n",
    "            features_11010 = np.append(features_11010, np.concatenate([features_1101[n,0:root_1101], features_1101[n,root_1101+1:M_1101]]))    \n",
    "        else:\n",
    "            features_11010 = np.vstack((features_11010, np.concatenate([features_1101[n,0:root_1101], features_1101[n,root_1101+1:M_1101]])))    \n",
    "        \n",
    "        labels_11010 = np.append(labels_11010, labels_1101[n])\n",
    "        m0 = m0 + 1\n",
    "\n",
    "        \n",
    "\n",
    "H_11010, cond_H_11010, mI_11010, mI_norm_11010, DG_11010, DG_norm_11010, ne_11010, gamma_vec_11010, error_vec_11010 = node_tree(features_11010,labels_11010)\n",
    "a_11010 = np.max(mI_1101)\n",
    "root_11010 = np.argmax(mI_1101)\n",
    "labels_root_11010 = gamma_vec_11010[:,root_11010]  \n",
    "errors_root_11010 = error_vec_11010[:,root_11010] \n",
    "\n",
    "print('ROOT_11010: choosing the node on the left of ROOT_1101 when its value is 0')\n",
    "print('node index, labels, and errors: press ENTER')\n",
    "if error_vec_11010[:,root_11010][0] == 0 and error_vec_11010[:,root_11010][1] == 0:\n",
    "    print(0)\n",
    "else:\n",
    "    print(indexes_410[root_11010])\n",
    "print(labels_root_11010)\n",
    "print(errors_root_11010)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfa4808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of test data\n",
      "59.0\n",
      "number of errors and empirical error rate on test data\n",
      "16 27.11864406779661\n"
     ]
    }
   ],
   "source": [
    "# Testing the resulting tree using the test data\n",
    "\n",
    "error = 0\n",
    "gamma_hat = 0\n",
    "\n",
    "for n in range(int(N_test)):\n",
    "    h = features_test[n, :]\n",
    "    gamma = labels_test[n]\n",
    "    if h[5] == 0:\n",
    "        if h[22] == 0:\n",
    "            if h[18] == 0:\n",
    "                if h[9] == 0:\n",
    "                    gamma_hat = 1 # 0 errors at end here\n",
    "                else:\n",
    "                    gamma_hat = 1 # 4 errors at end here\n",
    "            else:\n",
    "                if h[13] == 0:\n",
    "                    gamma_hat = -1 # 2 errors here\n",
    "                else:\n",
    "                    gamma_hat = 1 # 2 errors here\n",
    "        else:\n",
    "            if h[1] == 0:\n",
    "                gamma_hat = -1 # 0 errors\n",
    "            else:\n",
    "                if h[0] == 0:\n",
    "                    gamma_hat = -1 # 3 errors\n",
    "                else:\n",
    "                    gamma_hat = -1 # 5 errors\n",
    "    else:\n",
    "        if h[18] == 0:\n",
    "            if h[13] == 0:\n",
    "                if h[6] == 0:\n",
    "                    gamma_hat = 1 # 3 errors\n",
    "                else:\n",
    "                    gamma_hat = 1 # 0 error\n",
    "            else:\n",
    "                gamma_hat = 1\n",
    "                \n",
    "        else:\n",
    "            if h[24] == 0:\n",
    "                if h[0] == 0:\n",
    "                    gamma_hat = -1 # 0 error\n",
    "                else:\n",
    "                    if h[2] == 0:\n",
    "                        gamma_hat = 1 # 5 errors\n",
    "                    else:\n",
    "                        gamma_hat = -1 # 0 error\n",
    "            else:\n",
    "                if h[14] == 0:\n",
    "                    if h[10] == 0:\n",
    "                        gamma_hat = 1 # 1 error\n",
    "                    else:\n",
    "                        gamma_hat = -1 # 0 error\n",
    "                else:\n",
    "                    gamma_hat = 1 # 0 error\n",
    "\n",
    "    if gamma != gamma_hat:\n",
    "        error = error + 1\n",
    "\n",
    "\n",
    "    \n",
    "print('amount of test data')\n",
    "print(N_test)\n",
    "print('number of errors and empirical error rate on test data')\n",
    "print(error, (error/N_test)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a87c9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount of training data\n",
      "238\n",
      "number of errors and empirical error rate on training data\n",
      "32 13.445378151260504\n"
     ]
    }
   ],
   "source": [
    "error = 0\n",
    "gamma_hat = 0\n",
    "\n",
    "for n in range(int(N_train)):\n",
    "    h = features_train[n, :]\n",
    "    gamma = labels_train[n]\n",
    "    if h[5] == 0:\n",
    "        if h[22] == 0:\n",
    "            if h[18] == 0:\n",
    "                if h[9] == 0:\n",
    "                    gamma_hat = 1 # 0 errors at end here\n",
    "                else:\n",
    "                    gamma_hat = 1 # 4 errors at end here\n",
    "            else:\n",
    "                if h[13] == 0:\n",
    "                    gamma_hat = -1 # 2 errors here\n",
    "                else:\n",
    "                    gamma_hat = 1 # 2 errors here\n",
    "        else:\n",
    "            if h[1] == 0:\n",
    "                gamma_hat = -1 # 0 errors\n",
    "            else:\n",
    "                if h[0] == 0:\n",
    "                    gamma_hat = -1 # 3 errors\n",
    "                else:\n",
    "                    gamma_hat = -1 # 5 errors\n",
    "    else:\n",
    "        if h[18] == 0:\n",
    "            if h[13] == 0:\n",
    "                if h[6] == 0:\n",
    "                    gamma_hat = 1 # 3 errors\n",
    "                else:\n",
    "                    gamma_hat = 1 # 0 errors\n",
    "            else:\n",
    "                gamma_hat = 1 # 0 errors\n",
    "                \n",
    "        else:\n",
    "            if h[24] == 0:\n",
    "                if h[0] == 0:\n",
    "                    gamma_hat = -1 # 0 errors\n",
    "                else:\n",
    "                    if h[2] == 0:\n",
    "                        gamma_hat = 1 # 5 errors\n",
    "                    else:\n",
    "                        gamma_hat = -1 # 0 errors\n",
    "            else:\n",
    "                if h[14] == 0:\n",
    "                    if h[10] == 0:\n",
    "                        gamma_hat = 1 # 1 errors\n",
    "                    else:\n",
    "                        gamma_hat = -1 # 0 errors\n",
    "                else:\n",
    "                    gamma_hat = 1 # 0 errors\n",
    "\n",
    "    if gamma != gamma_hat:\n",
    "        error = error + 1\n",
    "\n",
    "\n",
    "    \n",
    "print('amount of training data')\n",
    "print(N_train)\n",
    "print('number of errors and empirical error rate on training data')\n",
    "print(error, (error/N_train)*100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
