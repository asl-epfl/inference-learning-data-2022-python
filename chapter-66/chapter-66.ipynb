{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_encoder(feature_data,t_hidden,t_output,n2,mu,rho,passes_ac):\n",
    "\n",
    "    # Initialization\n",
    "    L = 3 # total number of layers, including input and output layers --> ONE hidden layer\n",
    "    n1 = feature_data.shape[-1] # size of input layer, which is equal to M\n",
    "    nL = n1 # size of output layer, which is equal to the number of labels\n",
    "    n3 = n1 # number of nodes in fictitious layer 3\n",
    "    Q = nL # size of output layer; same as nL, which the number of classes as well.\n",
    "\n",
    "    W = (1/np.sqrt(n1))*np.random.randn(n2, n1)\n",
    "    theta = np.random.randn(n2)\n",
    "    Wx = (1/np.sqrt(n2))*np.random.randn(n1, n2)\n",
    "    thetax = np.random.randn(n1)\n",
    "\n",
    "    yCell = [None]*L # to save the y vectors across layers\n",
    "    zCell = [None]*L # to save the z vectors across layers\n",
    "    dCell = [None]*L # to save the sensitivity delta vectors\n",
    "    Wcell = [W, Wx] # a cell array containing the weight matrices of different dimensions\n",
    "    ThetaCell = [theta, thetax] # a cell array for the thetas\n",
    "\n",
    "    # Training using random reshuffling\n",
    "    N = feature_data.shape[0] # numbe of data points\n",
    "\n",
    "    for px in tqdm(range(passes_ac)):\n",
    "        Px = np.random.permutation(N) # using random reshuffling\n",
    "        for n in range(N): # training a neural network with one hidden layer\n",
    "            h = feature_data[Px[n]] # a column vector\n",
    "            gamma = h.copy()\n",
    "\n",
    "            y = h.copy()\n",
    "            yCell[0] = y.copy()\n",
    "\n",
    "            # FORWARD PROPAGATION\n",
    "            ell = 0 # first hidden layer\n",
    "            Weight = Wcell[ell]\n",
    "            theta = ThetaCell[ell]\n",
    "            y = yCell[ell]\n",
    "            z = Weight@y - theta\n",
    "            zCell[ell+1] = z.copy() # save z_{ell+1}\n",
    "\n",
    "            K = z.shape[0]\n",
    "            y = np.zeros(K) # let us now generate y_{ell+1}; same size as z\n",
    "\n",
    "            if t_hidden == 1: # sigmoid\n",
    "                y = 1/(1+np.exp(-z))\n",
    "            elif t_hidden == 2: # tanh\n",
    "                a = np.exp(z) - np.exp(-z)\n",
    "                b = np.exp(z) + np.exp(-z)\n",
    "                y = a/b \n",
    "            elif t_hidden == 3: # rectifier\n",
    "                y = np.array([max(0, z[k]) for k in range(K)])\n",
    "            elif t_hidden == 4: # linear\n",
    "                y = z.copy()\n",
    "            yCell[ell+1] = y.copy() # save y_{ell+1}\n",
    "\n",
    "            ell = 1 # output layer\n",
    "            Weight = Wcell[ell]\n",
    "            theta = ThetaCell[ell]\n",
    "            y = yCell[ell]\n",
    "            z = Weight@y - theta\n",
    "            zCell[ell+1] = z.copy() # save z_{ell+1}\n",
    "\n",
    "            K = z.shape[0]\n",
    "            y = np.zeros(K) # let us now generate y_{ell+1}; same size as z\n",
    "\n",
    "            if t_output == 1: # sigmoid\n",
    "                y = 1/(1+np.exp(-z))\n",
    "            elif t_output == 2: # tanh\n",
    "                a = np.exp(z) - np.exp(-z)\n",
    "                b = np.exp(z) + np.exp(-z)\n",
    "                y = a/b \n",
    "            elif t_output == 3: # rectifier\n",
    "                y = np.array([max(0, z[k]) for k in range(K)])\n",
    "            elif t_output == 4: # linear\n",
    "                y = z.copy()\n",
    "            yCell[ell+1] = y.copy() # save y_{ell+1}\n",
    "\n",
    "            zL = zCell[-1]\n",
    "            yL = yCell[-1]\n",
    "            K = zL.shape[0]\n",
    "            gamma_hat = yL.copy()\n",
    "\n",
    "            J = np.zeros((K, K))\n",
    "            if t_output == 1: # sigmoid\n",
    "                f = 1/(1+np.exp(-zL))\n",
    "                J = np.diag(f*(1-f)) # computing f'(z_L) in diagonal matrix form\n",
    "            elif t_output == 2: # tanh\n",
    "                b = np.exp(zL) + np.exp(-zL) # computing f'(z_L) in diagonal matrix form\n",
    "                J == np.diag(4/b**2)\n",
    "            elif t_output == 3: # rectifier\n",
    "                for k in range(K):\n",
    "                    if z[k] == 0: # set, by convention, f'(z) to zero at z=0 for the rectifier function\n",
    "                        J[k, k] = 0\n",
    "                    elif z[k] > 0:\n",
    "                        J[k, k] = 1\n",
    "                    elif z[k] < 0:\n",
    "                        J[k, k] = 0\n",
    "            elif t_output == 4: # linear\n",
    "                J = np.eye(K)\n",
    "            \n",
    "            deltaL = 2*J@(gamma_hat - gamma)\n",
    "            dCell[-1] = deltaL.copy() # boundary delta\n",
    "\n",
    "            # BACKPROPAGATION\n",
    "            ell = L - 1 # start the backward propagation\n",
    "            Weight_before = Wcell[ell-1]\n",
    "            theta_before = ThetaCell[ell-1]\n",
    "            y = yCell[ell-1]\n",
    "            delta = dCell[ell]\n",
    "\n",
    "            Weight = (1-2*mu*rho)*Weight_before - mu*delta*y.T\n",
    "            Wcell[ell-1] = Weight.copy() # update weight\n",
    "\n",
    "            theta = theta_before + mu*delta \n",
    "            ThetaCell[ell-1] = theta # update theta\n",
    "\n",
    "            if ell >= 2: # computing next delta only for ell >= 2\n",
    "                z = zCell[ell-1]\n",
    "                K = z.shape[0]\n",
    "                J = np.zeros((K, K))\n",
    "                #we should use here the activation of the HIDDEN layer\n",
    "                if t_hidden == 1: # sigmoid\n",
    "                    f = 1/(1+np.exp(-z))\n",
    "                    J = np.diag(f*(1-f))\n",
    "                elif t_hidden == 2: # tanh\n",
    "                    b = np.exp(z) + np.exp(-z)\n",
    "                    J = np.diag(4/b**2)\n",
    "                elif t_hidden == 3: # rectifier\n",
    "                    for k in range(K):\n",
    "                        if z[k] == 0: # set, by convention, f'(z) to zero at z=0 for the rectifier function\n",
    "                            J[k, k] = 0\n",
    "                        elif z[k] > 0:\n",
    "                            J[k, k] = 1\n",
    "                        elif z[k] < 0:\n",
    "                            J[k, k] = 0\n",
    "                elif t_hidden == 4: # linear\n",
    "                    J = np.eye(K)\n",
    "                dCell[ell-1] = J@((Weight_before).T@delta)\n",
    "\n",
    "            ell = 1 # next backward iteration\n",
    "            Weight_before = Wcell[ell-1]\n",
    "            theta_before = ThetaCell[ell-1]\n",
    "            y = yCell[ell-1]\n",
    "            delta = dCell[ell]\n",
    "\n",
    "            Weight = (1-2*mu*rho)*Weight_before - mu*delta@y.T \n",
    "            Wcell[ell-1] = Weight # update weight\n",
    "\n",
    "            theta = theta_before + mu*delta\n",
    "            ThetaCell[ell-1] = theta.copy() # update theta\n",
    "    W = Wcell[0]\n",
    "    theta = ThetaCell[0]\n",
    "    return W, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
